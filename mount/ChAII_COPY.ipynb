{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/abisubramanya27/ChAII-docker/blob/master/ChAII_COPY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTwSEAbMVIBn"
   },
   "source": [
    "Env Setup (Check out https://towardsdatascience.com/conda-google-colab-75f7c867a522 for detailed instructions)\n",
    "BEFORE STARTING, SET RUNTIME_TYPE TO GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVtit-4yq6rg"
   },
   "source": [
    "# ChAII starter notebook\n",
    "\n",
    "This is a starter notebook for running a baseline mBERT model on the task. This is a standalone notebook which will allow you to do the following:\n",
    "1. Train an mBERT model on the ChAII data (utilizing Colab GPUs), \n",
    "2. Get dev evaluation numbers, \n",
    "3. Generate a submission for the Kaggle leaderboard with the appropriate format.\n",
    "\n",
    "This notebook uses the [Xtreme](https://github.com/google-research/xtreme) codebase for training QA-finetuned models. Feel free to run your own scripts/variants locally, experiment with other models and pipelines, not necessarily limited to Xtreme. Here are some caveats of this method:\n",
    "1. Since runtimes (GPU/TPU) are re-allocated when the notebook is idle, Anaconda and dependencies installations need to be rerun everytime the notebook has to be reconnected.\n",
    "2. When runtime is disconnected, you lose all the files you have stored. Therefore you need to mount your Google Drive and store the relevant code and data there. Upon reconnection you can simply remount to access the data.\n",
    "\n",
    "Given the above conditions, we encourage you to have local installations (of Anaconda) and clones of the Xtreme codebase (with some changes mentioned below), use this notebook for training with GPU (and inference), and conduct evaluations locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W29gv5wKxB4v"
   },
   "source": [
    "## Environment + Xtreme Setup\n",
    "\n",
    "These steps set up Anaconda (Miniconda) on Colab, and set up the Xtreme Github codebase. \n",
    "\n",
    "**BEFORE YOU BEGIN:** Ensure you have set runtime as GPU before running. These set of cells have to rerun everytime you disconnect/change runtime.\n",
    "\n",
    "Colab navigation: With Colab, you can access your folders and files with the upper-left icon. Your files will be stored in ```/content/```. \n",
    "\n",
    "Useful links:\n",
    "1. Mounting your Google Drive, Cloud Storage: [link](https://colab.sandbox.google.com/notebooks/io.ipynb#scrollTo=eikfzi8ZT_rW)\n",
    "2. Setting up Miniconda on Colab: [link](https://towardsdatascience.com/conda-google-colab-75f7c867a522)\n",
    "3. Xtreme Github Repo: [link](https://github.com/google-research/xtreme)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-i_Rxpy4paf"
   },
   "source": [
    "### Anaconda (Miniconda) Setup\n",
    "\n",
    "See [this link](https://towardsdatascience.com/conda-google-colab-75f7c867a522) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Zqk1MjtVndG",
    "outputId": "db2c31d4-283b-4a2c-e3db-7596e5c8b541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Verify PYTHONPATH is blank to avoid problems later\n",
    "!echo $PYTHONPATH # should return <blank>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_-aluEdaDTO",
    "outputId": "1d505c78-8b7a-4f34-f3b2-8e10f21eed93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/conda\n",
      "conda 4.10.3\n",
      "/usr/local/bin/python\n",
      "Python 3.7.10\n"
     ]
    }
   ],
   "source": [
    "# Verify that Miniconda installation and updation worked\n",
    "\n",
    "!which conda # should return /usr/local/bin/conda\n",
    "!conda --version # should return 4.10.3\n",
    "!which python # should return /usr/local/bin/python\n",
    "!python --version # should return Python 3.6.13 :: Anaconda, Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hmrAJyYMabHA",
    "outputId": "2c4fa3ed-9a53-44b7-acf9-162c176acd76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/root/mount',\n",
       " '/usr/local/lib/python37.zip',\n",
       " '/usr/local/lib/python3.7',\n",
       " '/usr/local/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.7/site-packages',\n",
       " '/usr/local/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/root/.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of path files\n",
    "\n",
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XA9sYrV4akGw",
    "outputId": "01d98d3f-d4e8-453d-d322-8d51dfedad5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip  pip-21.2.1.dist-info\r\n"
     ]
    }
   ],
   "source": [
    "# View different installed packages\n",
    "\n",
    "!ls /usr/local/lib/python3.7/dist-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m0Ppwdu0anYJ"
   },
   "outputs": [],
   "source": [
    "# Appending to sys path. This is where your installs will be located\n",
    "\n",
    "import sys\n",
    "_ = (sys.path\n",
    "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0cl_SMOa2AN",
    "outputId": "33bc492c-1f35-4422-c8b4-d96cbbf50b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
      "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/linux-64::asn1crypto==0.24.0=py36_0\n",
      "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local\n",
      "\n",
      "  added / updated specs:\n",
      "    - featuretools\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    asn1crypto-1.4.0           |     pyh9f0ad1d_0          78 KB  conda-forge\n",
      "    bokeh-2.3.3                |   py37h89c1867_0         8.2 MB  conda-forge\n",
      "    ca-certificates-2021.5.30  |       ha878542_0         136 KB  conda-forge\n",
      "    certifi-2021.5.30          |   py37h89c1867_0         141 KB  conda-forge\n",
      "    click-8.0.1                |   py37h89c1867_0         145 KB  conda-forge\n",
      "    cloudpickle-1.6.0          |             py_0          22 KB  conda-forge\n",
      "    conda-4.10.3               |   py37h89c1867_0         3.1 MB  conda-forge\n",
      "    cytoolz-0.11.0             |   py37h5e8e339_3         403 KB  conda-forge\n",
      "    dask-2021.7.1              |     pyhd8ed1ab_0           4 KB  conda-forge\n",
      "    dask-core-2021.7.1         |     pyhd8ed1ab_0         750 KB  conda-forge\n",
      "    distributed-2021.7.1       |   py37h89c1867_0         1.0 MB  conda-forge\n",
      "    featuretools-0.26.1        |     pyhd8ed1ab_0         297 KB  conda-forge\n",
      "    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n",
      "    fsspec-2021.7.0            |     pyhd8ed1ab_0          81 KB  conda-forge\n",
      "    heapdict-1.0.1             |             py_0           7 KB  conda-forge\n",
      "    importlib-metadata-4.6.1   |   py37h89c1867_0          31 KB  conda-forge\n",
      "    jbig-2.1                   |    h7f98852_2003          43 KB  conda-forge\n",
      "    jinja2-3.0.1               |     pyhd8ed1ab_0          99 KB  conda-forge\n",
      "    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n",
      "    lcms2-2.12                 |       hddcbb42_0         443 KB  conda-forge\n",
      "    lerc-2.2.1                 |       h9c3ff4c_0         213 KB  conda-forge\n",
      "    libblas-3.9.0              |       9_openblas          11 KB  conda-forge\n",
      "    libcblas-3.9.0             |       9_openblas          11 KB  conda-forge\n",
      "    libdeflate-1.7             |       h7f98852_5          67 KB  conda-forge\n",
      "    libgfortran-ng-11.1.0      |       h69a702a_0          18 KB  conda-forge\n",
      "    libgfortran5-11.1.0        |       h6c583b3_0         1.7 MB  conda-forge\n",
      "    liblapack-3.9.0            |       9_openblas          11 KB  conda-forge\n",
      "    libopenblas-0.3.15         |pthreads_h8fe5266_1         9.2 MB  conda-forge\n",
      "    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n",
      "    libtiff-4.3.0              |       hf544144_1         668 KB  conda-forge\n",
      "    libwebp-base-1.2.0         |       h7f98852_2         815 KB  conda-forge\n",
      "    locket-0.2.0               |             py_2           6 KB  conda-forge\n",
      "    lz4-c-1.9.3                |       h9c3ff4c_0         179 KB  conda-forge\n",
      "    markupsafe-2.0.1           |   py37h5e8e339_0          22 KB  conda-forge\n",
      "    msgpack-python-1.0.2       |   py37h2527ec5_1          91 KB  conda-forge\n",
      "    numpy-1.21.1               |   py37h038b26d_0         6.1 MB  conda-forge\n",
      "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
      "    openjpeg-2.4.0             |       hb52868f_1         444 KB  conda-forge\n",
      "    openssl-1.1.1k             |       h7f98852_0         2.1 MB  conda-forge\n",
      "    packaging-21.0             |     pyhd8ed1ab_0          35 KB  conda-forge\n",
      "    pandas-1.3.1               |   py37h219a48f_0        12.7 MB  conda-forge\n",
      "    partd-1.2.0                |     pyhd8ed1ab_0          18 KB  conda-forge\n",
      "    pillow-8.3.1               |   py37h0f21c89_0         692 KB  conda-forge\n",
      "    psutil-5.8.0               |   py37h5e8e339_1         342 KB  conda-forge\n",
      "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
      "    python-dateutil-2.8.2      |     pyhd8ed1ab_0         240 KB  conda-forge\n",
      "    python_abi-3.7             |          2_cp37m           4 KB  conda-forge\n",
      "    pytz-2021.1                |     pyhd8ed1ab_0         239 KB  conda-forge\n",
      "    pyyaml-5.4.1               |   py37h5e8e339_0         189 KB  conda-forge\n",
      "    scipy-1.7.0                |   py37h29e03ee_1        21.7 MB  conda-forge\n",
      "    sortedcontainers-2.4.0     |     pyhd8ed1ab_0          26 KB  conda-forge\n",
      "    tblib-1.7.0                |     pyhd8ed1ab_0          15 KB  conda-forge\n",
      "    toolz-0.11.1               |             py_0          46 KB  conda-forge\n",
      "    tornado-6.1                |   py37h5e8e339_1         646 KB  conda-forge\n",
      "    typing_extensions-3.10.0.0 |     pyha770c72_0          28 KB  conda-forge\n",
      "    zict-2.0.0                 |             py_0          10 KB  conda-forge\n",
      "    zipp-3.5.0                 |     pyhd8ed1ab_0          12 KB  conda-forge\n",
      "    zstd-1.5.0                 |       ha95c52a_0         490 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        75.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bokeh              conda-forge/linux-64::bokeh-2.3.3-py37h89c1867_0\n",
      "  click              conda-forge/linux-64::click-8.0.1-py37h89c1867_0\n",
      "  cloudpickle        conda-forge/noarch::cloudpickle-1.6.0-py_0\n",
      "  cytoolz            conda-forge/linux-64::cytoolz-0.11.0-py37h5e8e339_3\n",
      "  dask               conda-forge/noarch::dask-2021.7.1-pyhd8ed1ab_0\n",
      "  dask-core          conda-forge/noarch::dask-core-2021.7.1-pyhd8ed1ab_0\n",
      "  distributed        conda-forge/linux-64::distributed-2021.7.1-py37h89c1867_0\n",
      "  featuretools       conda-forge/noarch::featuretools-0.26.1-pyhd8ed1ab_0\n",
      "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
      "  fsspec             conda-forge/noarch::fsspec-2021.7.0-pyhd8ed1ab_0\n",
      "  heapdict           conda-forge/noarch::heapdict-1.0.1-py_0\n",
      "  importlib-metadata conda-forge/linux-64::importlib-metadata-4.6.1-py37h89c1867_0\n",
      "  jbig               conda-forge/linux-64::jbig-2.1-h7f98852_2003\n",
      "  jinja2             conda-forge/noarch::jinja2-3.0.1-pyhd8ed1ab_0\n",
      "  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n",
      "  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\n",
      "  lerc               conda-forge/linux-64::lerc-2.2.1-h9c3ff4c_0\n",
      "  libblas            conda-forge/linux-64::libblas-3.9.0-9_openblas\n",
      "  libcblas           conda-forge/linux-64::libcblas-3.9.0-9_openblas\n",
      "  libdeflate         conda-forge/linux-64::libdeflate-1.7-h7f98852_5\n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-11.1.0-h69a702a_0\n",
      "  libgfortran5       conda-forge/linux-64::libgfortran5-11.1.0-h6c583b3_0\n",
      "  liblapack          conda-forge/linux-64::liblapack-3.9.0-9_openblas\n",
      "  libopenblas        conda-forge/linux-64::libopenblas-0.3.15-pthreads_h8fe5266_1\n",
      "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
      "  libtiff            conda-forge/linux-64::libtiff-4.3.0-hf544144_1\n",
      "  libwebp-base       conda-forge/linux-64::libwebp-base-1.2.0-h7f98852_2\n",
      "  locket             conda-forge/noarch::locket-0.2.0-py_2\n",
      "  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_0\n",
      "  markupsafe         conda-forge/linux-64::markupsafe-2.0.1-py37h5e8e339_0\n",
      "  msgpack-python     conda-forge/linux-64::msgpack-python-1.0.2-py37h2527ec5_1\n",
      "  numpy              conda-forge/linux-64::numpy-1.21.1-py37h038b26d_0\n",
      "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
      "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hb52868f_1\n",
      "  packaging          conda-forge/noarch::packaging-21.0-pyhd8ed1ab_0\n",
      "  pandas             conda-forge/linux-64::pandas-1.3.1-py37h219a48f_0\n",
      "  partd              conda-forge/noarch::partd-1.2.0-pyhd8ed1ab_0\n",
      "  pillow             conda-forge/linux-64::pillow-8.3.1-py37h0f21c89_0\n",
      "  psutil             conda-forge/linux-64::psutil-5.8.0-py37h5e8e339_1\n",
      "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.7-2_cp37m\n",
      "  pytz               conda-forge/noarch::pytz-2021.1-pyhd8ed1ab_0\n",
      "  pyyaml             conda-forge/linux-64::pyyaml-5.4.1-py37h5e8e339_0\n",
      "  scipy              conda-forge/linux-64::scipy-1.7.0-py37h29e03ee_1\n",
      "  sortedcontainers   conda-forge/noarch::sortedcontainers-2.4.0-pyhd8ed1ab_0\n",
      "  tblib              conda-forge/noarch::tblib-1.7.0-pyhd8ed1ab_0\n",
      "  toolz              conda-forge/noarch::toolz-0.11.1-py_0\n",
      "  tornado            conda-forge/linux-64::tornado-6.1-py37h5e8e339_1\n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-3.10.0.0-pyha770c72_0\n",
      "  zict               conda-forge/noarch::zict-2.0.0-py_0\n",
      "  zipp               conda-forge/noarch::zipp-3.5.0-pyhd8ed1ab_0\n",
      "  zstd               conda-forge/linux-64::zstd-1.5.0-ha95c52a_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  asn1crypto         pkgs/main/linux-64::asn1crypto-0.24.0~ --> conda-forge/noarch::asn1crypto-1.4.0-pyh9f0ad1d_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.7.5-h~ --> conda-forge::ca-certificates-2021.5.30-ha878542_0\n",
      "  certifi            pkgs/main::certifi-2021.5.30-py37h06a~ --> conda-forge::certifi-2021.5.30-py37h89c1867_0\n",
      "  conda              pkgs/main::conda-4.10.3-py37h06a4308_0 --> conda-forge::conda-4.10.3-py37h89c1867_0\n",
      "  openssl              pkgs/main::openssl-1.1.1k-h27cfd23_0 --> conda-forge::openssl-1.1.1k-h7f98852_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "zstd-1.5.0           | 490 KB    | : 100% 1.0/1 [00:00<00:00,  3.58it/s]\n",
      "psutil-5.8.0         | 342 KB    | : 100% 1.0/1 [00:00<00:00,  7.28it/s]\n",
      "tblib-1.7.0          | 15 KB     | : 100% 1.0/1 [00:00<00:00, 20.67it/s]\n",
      "toolz-0.11.1         | 46 KB     | : 100% 1.0/1 [00:00<00:00, 14.54it/s]\n",
      "pytz-2021.1          | 239 KB    | : 100% 1.0/1 [00:00<00:00,  7.45it/s]\n",
      "zict-2.0.0           | 10 KB     | : 100% 1.0/1 [00:00<00:00, 22.02it/s]\n",
      "numpy-1.21.1         | 6.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.21s/it]\n",
      "jpeg-9d              | 264 KB    | : 100% 1.0/1 [00:00<00:00, 10.67it/s]\n",
      "jinja2-3.0.1         | 99 KB     | : 100% 1.0/1 [00:00<00:00, 15.72it/s]\n",
      "scipy-1.7.0          | 21.7 MB   | : 100% 1.0/1 [00:03<00:00,  3.38s/it]               \n",
      "dask-2021.7.1        | 4 KB      | : 100% 1.0/1 [00:00<00:00, 16.04it/s]\n",
      "ca-certificates-2021 | 136 KB    | : 100% 1.0/1 [00:00<00:00, 15.19it/s]\n",
      "libtiff-4.3.0        | 668 KB    | : 100% 1.0/1 [00:00<00:00,  5.91it/s]\n",
      "heapdict-1.0.1       | 7 KB      | : 100% 1.0/1 [00:00<00:00, 22.78it/s]\n",
      "olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 17.21it/s]\n",
      "cloudpickle-1.6.0    | 22 KB     | : 100% 1.0/1 [00:00<00:00, 16.34it/s]\n",
      "markupsafe-2.0.1     | 22 KB     | : 100% 1.0/1 [00:00<00:00, 16.93it/s]\n",
      "tornado-6.1          | 646 KB    | : 100% 1.0/1 [00:00<00:00,  5.28it/s]\n",
      "fsspec-2021.7.0      | 81 KB     | : 100% 1.0/1 [00:00<00:00, 13.74it/s]\n",
      "partd-1.2.0          | 18 KB     | : 100% 1.0/1 [00:00<00:00, 18.93it/s]\n",
      "zipp-3.5.0           | 12 KB     | : 100% 1.0/1 [00:00<00:00, 19.03it/s]\n",
      "featuretools-0.26.1  | 297 KB    | : 100% 1.0/1 [00:00<00:00,  6.12it/s]\n",
      "cytoolz-0.11.0       | 403 KB    | : 100% 1.0/1 [00:00<00:00,  8.14it/s]\n",
      "lerc-2.2.1           | 213 KB    | : 100% 1.0/1 [00:00<00:00, 11.12it/s]\n",
      "libpng-1.6.37        | 306 KB    | : 100% 1.0/1 [00:00<00:00,  9.31it/s]\n",
      "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 19.96it/s]\n",
      "jbig-2.1             | 43 KB     | : 100% 1.0/1 [00:00<00:00, 20.42it/s]\n",
      "lz4-c-1.9.3          | 179 KB    | : 100% 1.0/1 [00:00<00:00, 11.93it/s]\n",
      "libgfortran5-11.1.0  | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.99it/s]\n",
      "conda-4.10.3         | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.59it/s]               \n",
      "lcms2-2.12           | 443 KB    | : 100% 1.0/1 [00:00<00:00,  8.39it/s]\n",
      "openjpeg-2.4.0       | 444 KB    | : 100% 1.0/1 [00:00<00:00,  8.70it/s]\n",
      "importlib-metadata-4 | 31 KB     | : 100% 1.0/1 [00:00<00:00, 13.97it/s]\n",
      "libblas-3.9.0        | 11 KB     | : 100% 1.0/1 [00:00<00:00, 23.95it/s]\n",
      "openssl-1.1.1k       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.59it/s]\n",
      "pillow-8.3.1         | 692 KB    | : 100% 1.0/1 [00:00<00:00,  5.31it/s]\n",
      "libgfortran-ng-11.1. | 18 KB     | : 100% 1.0/1 [00:00<00:00, 20.40it/s]\n",
      "pyparsing-2.4.7      | 60 KB     | : 100% 1.0/1 [00:00<00:00, 20.20it/s]\n",
      "sortedcontainers-2.4 | 26 KB     | : 100% 1.0/1 [00:00<00:00, 20.74it/s]\n",
      "typing_extensions-3. | 28 KB     | : 100% 1.0/1 [00:00<00:00, 22.68it/s]\n",
      "certifi-2021.5.30    | 141 KB    | : 100% 1.0/1 [00:00<00:00, 13.94it/s]\n",
      "distributed-2021.7.1 | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.89it/s]\n",
      "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 22.44it/s]\n",
      "python-dateutil-2.8. | 240 KB    | : 100% 1.0/1 [00:00<00:00, 13.23it/s]\n",
      "bokeh-2.3.3          | 8.2 MB    | : 100% 1.0/1 [00:02<00:00,  2.12s/it]               \n",
      "libdeflate-1.7       | 67 KB     | : 100% 1.0/1 [00:00<00:00, 12.88it/s]\n",
      "dask-core-2021.7.1   | 750 KB    | : 100% 1.0/1 [00:00<00:00,  4.33it/s]\n",
      "packaging-21.0       | 35 KB     | : 100% 1.0/1 [00:00<00:00, 20.94it/s]\n",
      "click-8.0.1          | 145 KB    | : 100% 1.0/1 [00:00<00:00,  9.78it/s]\n",
      "msgpack-python-1.0.2 | 91 KB     | : 100% 1.0/1 [00:00<00:00, 15.22it/s]\n",
      "python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 23.86it/s]\n",
      "pyyaml-5.4.1         | 189 KB    | : 100% 1.0/1 [00:00<00:00, 12.49it/s]\n",
      "asn1crypto-1.4.0     | 78 KB     | : 100% 1.0/1 [00:00<00:00, 15.53it/s]\n",
      "pandas-1.3.1         | 12.7 MB   | : 100% 1.0/1 [00:02<00:00,  2.66s/it]\n",
      "libopenblas-0.3.15   | 9.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.60s/it]               \n",
      "locket-0.2.0         | 6 KB      | : 100% 1.0/1 [00:00<00:00, 15.77it/s]\n",
      "libwebp-base-1.2.0   | 815 KB    | : 100% 1.0/1 [00:00<00:00,  4.94it/s]\n",
      "freetype-2.10.4      | 890 KB    | : 100% 1.0/1 [00:00<00:00,  5.40it/s]\n",
      "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
      "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
      "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n"
     ]
    }
   ],
   "source": [
    "# To install any packages, run a command similar to the one below, pip also works\n",
    "!conda install --channel conda-forge featuretools --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhFA-xKkbHTd"
   },
   "source": [
    "### Xtreme codebase setup\n",
    "\n",
    "Now, we will set up the Xtreme repo ([link](https://github.com/google-research/xtreme)). The below cells do the following:\n",
    "1. Clone Xtreme\n",
    "2. Create a Conda env called ```xtreme``` and install dependencies into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFxzWzJga9hk",
    "outputId": "3049c581-b104-4934-b909-901e515b4d86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: cd: drive/MyDrive/: No such file or directory\n",
      "Cloning into 'xtreme'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd drive/MyDrive/ # Optional but recommended as we will be modifying Xtreme code below\n",
    "git clone https://github.com/google-research/xtreme.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4Bu1kblBWy8"
   },
   "source": [
    "This cell below is a modified version of ```xtreme/install_tools.sh```. \n",
    "\n",
    "**Note:** who are using Xtreme repo locally may also encounter errors with the original script, such as with ```conda activate```. You can copy-paste this script to resolve the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsj_ukAgbYIs",
    "outputId": "666d8b19-4b86-4bf7-f294-606ed58018e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and Extracting Packages\n",
      "\r",
      "blas-1.0             |            |   0% \r",
      "blas-1.0             | ########## | 100% \r",
      "blas-1.0             | ########## | 100% \n",
      "\r",
      "ca-certificates-2020 |            |   0% \r",
      "ca-certificates-2020 | #2         |  12% \r",
      "ca-certificates-2020 | ########## | 100% \n",
      "\r",
      "cudatoolkit-10.0.130 |            |   0% \r",
      "cudatoolkit-10.0.130 |            |   0% \r",
      "cudatoolkit-10.0.130 | 3          |   4% \r",
      "cudatoolkit-10.0.130 | 8          |   8% \r",
      "cudatoolkit-10.0.130 | #2         |  13% \r",
      "cudatoolkit-10.0.130 | #7         |  17% \r",
      "cudatoolkit-10.0.130 | ##1        |  21% \r",
      "cudatoolkit-10.0.130 | ##5        |  25% \r",
      "cudatoolkit-10.0.130 | ##8        |  29% \r",
      "cudatoolkit-10.0.130 | ###3       |  33% \r",
      "cudatoolkit-10.0.130 | ###7       |  37% \r",
      "cudatoolkit-10.0.130 | ####       |  41% \r",
      "cudatoolkit-10.0.130 | ####4      |  45% \r",
      "cudatoolkit-10.0.130 | ####8      |  49% \r",
      "cudatoolkit-10.0.130 | #####2     |  53% \r",
      "cudatoolkit-10.0.130 | #####6     |  56% \r",
      "cudatoolkit-10.0.130 | #####9     |  60% \r",
      "cudatoolkit-10.0.130 | ######2    |  63% \r",
      "cudatoolkit-10.0.130 | ######5    |  66% \r",
      "cudatoolkit-10.0.130 | ######9    |  69% \r",
      "cudatoolkit-10.0.130 | #######3   |  73% \r",
      "cudatoolkit-10.0.130 | #######7   |  77% \r",
      "cudatoolkit-10.0.130 | ########1  |  81% \r",
      "cudatoolkit-10.0.130 | ########4  |  85% \r",
      "cudatoolkit-10.0.130 | ########8  |  88% \r",
      "cudatoolkit-10.0.130 | #########1 |  92% \r",
      "cudatoolkit-10.0.130 | #########5 |  96% \r",
      "cudatoolkit-10.0.130 | #########9 |  99% \r",
      "cudatoolkit-10.0.130 | ########## | 100% \n",
      "\r",
      "intel-openmp-2019.4  |            |   0% \r",
      "intel-openmp-2019.4  | 1          |   2% \r",
      "intel-openmp-2019.4  | ########## | 100% \r",
      "intel-openmp-2019.4  | ########## | 100% \n",
      "\r",
      "libgfortran-ng-7.3.0 |            |   0% \r",
      "libgfortran-ng-7.3.0 | ########## | 100% \r",
      "libgfortran-ng-7.3.0 | ########## | 100% \n",
      "\r",
      "mkl-2019.4           |            |   0% \r",
      "mkl-2019.4           |            |   0% \r",
      "mkl-2019.4           |            |   0% \r",
      "mkl-2019.4           | 1          |   1% \r",
      "mkl-2019.4           | 2          |   3% \r",
      "mkl-2019.4           | 4          |   4% \r",
      "mkl-2019.4           | 5          |   6% \r",
      "mkl-2019.4           | 6          |   7% \r",
      "mkl-2019.4           | 8          |   8% \r",
      "mkl-2019.4           | 9          |   9% \r",
      "mkl-2019.4           | #          |  11% \r",
      "mkl-2019.4           | #2         |  12% \r",
      "mkl-2019.4           | #3         |  13% \r",
      "mkl-2019.4           | #4         |  15% \r",
      "mkl-2019.4           | #6         |  16% \r",
      "mkl-2019.4           | #7         |  18% \r",
      "mkl-2019.4           | #8         |  19% \r",
      "mkl-2019.4           | ##         |  20% \r",
      "mkl-2019.4           | ##1        |  22% \r",
      "mkl-2019.4           | ##3        |  23% \r",
      "mkl-2019.4           | ##4        |  25% \r",
      "mkl-2019.4           | ##6        |  26% \r",
      "mkl-2019.4           | ##7        |  27% \r",
      "mkl-2019.4           | ##8        |  29% \r",
      "mkl-2019.4           | ###        |  31% \r",
      "mkl-2019.4           | ###1       |  32% \r",
      "mkl-2019.4           | ###3       |  33% \r",
      "mkl-2019.4           | ###4       |  35% \r",
      "mkl-2019.4           | ###6       |  36% \r",
      "mkl-2019.4           | ###7       |  38% \r",
      "mkl-2019.4           | ###8       |  39% \r",
      "mkl-2019.4           | ####       |  40% \r",
      "mkl-2019.4           | ####1      |  42% \r",
      "mkl-2019.4           | ####3      |  43% \r",
      "mkl-2019.4           | ####4      |  45% \r",
      "mkl-2019.4           | ####6      |  46% \r",
      "mkl-2019.4           | ####7      |  47% \r",
      "mkl-2019.4           | ####8      |  49% \r",
      "mkl-2019.4           | #####      |  50% \r",
      "mkl-2019.4           | #####1     |  52% \r",
      "mkl-2019.4           | #####2     |  53% \r",
      "mkl-2019.4           | #####4     |  54% \r",
      "mkl-2019.4           | #####5     |  56% \r",
      "mkl-2019.4           | #####7     |  57% \r",
      "mkl-2019.4           | #####8     |  59% \r",
      "mkl-2019.4           | #####9     |  60% \r",
      "mkl-2019.4           | ######1    |  61% \r",
      "mkl-2019.4           | ######2    |  62% \r",
      "mkl-2019.4           | ######4    |  64% \r",
      "mkl-2019.4           | ######5    |  65% \r",
      "mkl-2019.4           | ######6    |  67% \r",
      "mkl-2019.4           | ######8    |  68% \r",
      "mkl-2019.4           | ######9    |  70% \r",
      "mkl-2019.4           | #######    |  71% \r",
      "mkl-2019.4           | #######2   |  72% \r",
      "mkl-2019.4           | #######3   |  74% \r",
      "mkl-2019.4           | #######5   |  75% \r",
      "mkl-2019.4           | #######6   |  77% \r",
      "mkl-2019.4           | #######7   |  78% \r",
      "mkl-2019.4           | #######9   |  79% \r",
      "mkl-2019.4           | ########   |  81% \r",
      "mkl-2019.4           | ########1  |  82% \r",
      "mkl-2019.4           | ########3  |  83% \r",
      "mkl-2019.4           | ########4  |  85% \r",
      "mkl-2019.4           | ########6  |  86% \r",
      "mkl-2019.4           | ########7  |  88% \r",
      "mkl-2019.4           | ########8  |  89% \r",
      "mkl-2019.4           | #########  |  90% \r",
      "mkl-2019.4           | #########1 |  92% \r",
      "mkl-2019.4           | #########3 |  93% \r",
      "mkl-2019.4           | #########4 |  94% \r",
      "mkl-2019.4           | #########5 |  96% \r",
      "mkl-2019.4           | #########7 |  97% \r",
      "mkl-2019.4           | #########8 |  99% \r",
      "mkl-2019.4           | ########## | 100% \r",
      "mkl-2019.4           | ########## | 100% \n",
      "\r",
      "expat-2.2.6          |            |   0% \r",
      "expat-2.2.6          | ########## | 100% \r",
      "expat-2.2.6          | ########## | 100% \n",
      "\r",
      "gmp-6.1.2            |            |   0% \r",
      "gmp-6.1.2            | 2          |   2% \r",
      "gmp-6.1.2            | ########## | 100% \r",
      "gmp-6.1.2            | ########## | 100% \n",
      "\r",
      "icu-58.2             |            |   0% \r",
      "icu-58.2             |            |   0% \r",
      "icu-58.2             | 8          |   9% \r",
      "icu-58.2             | #5         |  15% \r",
      "icu-58.2             | ##1        |  22% \r",
      "icu-58.2             | ##8        |  29% \r",
      "icu-58.2             | ###5       |  35% \r",
      "icu-58.2             | ####1      |  41% \r",
      "icu-58.2             | ####8      |  48% \r",
      "icu-58.2             | #####4     |  54% \r",
      "icu-58.2             | ######     |  61% \r",
      "icu-58.2             | ######7    |  67% \r",
      "icu-58.2             | #######3   |  73% \r",
      "icu-58.2             | #######9   |  80% \r",
      "icu-58.2             | ########6  |  86% \r",
      "icu-58.2             | #########2 |  93% \r",
      "icu-58.2             | #########9 |  99% \r",
      "icu-58.2             | ########## | 100% \n",
      "\r",
      "jpeg-9b              |            |   0% \r",
      "jpeg-9b              | ########## | 100% \n",
      "\r",
      "libsodium-1.0.16     |            |   0% \r",
      "libsodium-1.0.16     | 5          |   5% \r",
      "libsodium-1.0.16     | ########## | 100% \n",
      "\r",
      "libuuid-1.0.3        |            |   0% \r",
      "libuuid-1.0.3        | ########## | 100% \n",
      "\r",
      "libxcb-1.13          |            |   0% \r",
      "libxcb-1.13          | 3          |   3% \r",
      "libxcb-1.13          | ########## | 100% \r",
      "libxcb-1.13          | ########## | 100% \n",
      "\r",
      "ncurses-6.1          |            |   0% \r",
      "ncurses-6.1          | ########## | 100% \r",
      "ncurses-6.1          | ########## | 100% \n",
      "\r",
      "openssl-1.1.1g       |            |   0% \r",
      "openssl-1.1.1g       |            |   0% \r",
      "openssl-1.1.1g       | ###        |  30% \r",
      "openssl-1.1.1g       | ######3    |  63% \r",
      "openssl-1.1.1g       | ########## | 100% \r",
      "openssl-1.1.1g       | ########## | 100% \n",
      "\r",
      "pcre-8.43            |            |   0% \r",
      "pcre-8.43            | 6          |   6% \r",
      "pcre-8.43            | ########## | 100% \n",
      "\r",
      "glib-2.56.2          |            |   0% \r",
      "glib-2.56.2          | ######9    |  70% \r",
      "glib-2.56.2          | ########## | 100% \n",
      "\r",
      "libedit-3.1.20181209 |            |   0% \r",
      "libedit-3.1.20181209 | ########## | 100% \n",
      "\r",
      "libpng-1.6.37        |            |   0% \r",
      "libpng-1.6.37        | ########## | 100% \n",
      "\r",
      "libxml2-2.9.9        |            |   0% \r",
      "libxml2-2.9.9        |            |   1% \r",
      "libxml2-2.9.9        | ######4    |  65% \r",
      "libxml2-2.9.9        | ########## | 100% \n",
      "\r",
      "pandoc-2.2.3.2       |            |   0% \r",
      "pandoc-2.2.3.2       |            |   0% \r",
      "pandoc-2.2.3.2       | 1          |   2% \r",
      "pandoc-2.2.3.2       | 6          |   6% \r",
      "pandoc-2.2.3.2       | #7         |  17% \r",
      "pandoc-2.2.3.2       | ###        |  31% \r",
      "pandoc-2.2.3.2       | ####3      |  44% \r",
      "pandoc-2.2.3.2       | #####8     |  58% \r",
      "pandoc-2.2.3.2       | #######    |  70% \r",
      "pandoc-2.2.3.2       | ########4  |  85% \r",
      "pandoc-2.2.3.2       | #########7 |  97% \r",
      "pandoc-2.2.3.2       | ########## | 100% \n",
      "\r",
      "readline-7.0         |            |   0% \r",
      "readline-7.0         | ########## | 100% \r",
      "readline-7.0         | ########## | 100% \n",
      "\r",
      "tk-8.6.8             |            |   0% \r",
      "tk-8.6.8             | ########## | 100% \r",
      "tk-8.6.8             | ########## | 100% \n",
      "\r",
      "zeromq-4.3.1         |            |   0% \r",
      "zeromq-4.3.1         | 2          |   2% \r",
      "zeromq-4.3.1         | #####      |  50% \r",
      "zeromq-4.3.1         | ########## | 100% \r",
      "zeromq-4.3.1         | ########## | 100% \n",
      "\r",
      "zstd-1.3.7           |            |   0% \r",
      "zstd-1.3.7           | ########## | 100% \r",
      "zstd-1.3.7           | ########## | 100% \n",
      "\r",
      "dbus-1.13.12         |            |   0% \r",
      "dbus-1.13.12         | 2          |   3% \r",
      "dbus-1.13.12         | ########## | 100% \r",
      "dbus-1.13.12         | ########## | 100% \n",
      "\r",
      "freetype-2.9.1       |            |   0% \r",
      "freetype-2.9.1       | ########## | 100% \r",
      "freetype-2.9.1       | ########## | 100% \n",
      "\r",
      "gstreamer-1.14.0     |            |   0% \r",
      "gstreamer-1.14.0     | ########## | 100% \r",
      "gstreamer-1.14.0     | ########## | 100% \n",
      "\r",
      "libtiff-4.1.0        |            |   0% \r",
      "libtiff-4.1.0        | ########## | 100% \r",
      "libtiff-4.1.0        | ########## | 100% \n",
      "\r",
      "sqlite-3.30.1        |            |   0% \r",
      "sqlite-3.30.1        |            |   1% \r",
      "sqlite-3.30.1        | ########   |  81% \r",
      "sqlite-3.30.1        | ########## | 100% \n",
      "\r",
      "fontconfig-2.13.0    |            |   0% \r",
      "fontconfig-2.13.0    | ########## | 100% \n",
      "\r",
      "gst-plugins-base-1.1 |            |   0% \r",
      "gst-plugins-base-1.1 | #########5 |  95% \r",
      "gst-plugins-base-1.1 | ########## | 100% \n",
      "\r",
      "python-3.7.5         |            |   0% \r",
      "python-3.7.5         |            |   0% \r",
      "python-3.7.5         | 2          |   2% \r",
      "python-3.7.5         | 5          |   6% \r",
      "python-3.7.5         | #          |  10% \r",
      "python-3.7.5         | #3         |  14% \r",
      "python-3.7.5         | #7         |  18% \r",
      "python-3.7.5         | ##1        |  21% \r",
      "python-3.7.5         | ##5        |  25% \r",
      "python-3.7.5         | ##9        |  29% \r",
      "python-3.7.5         | ###3       |  33% \r",
      "python-3.7.5         | ###7       |  37% \r",
      "python-3.7.5         | ####1      |  41% \r",
      "python-3.7.5         | ####5      |  45% \r",
      "python-3.7.5         | ####9      |  49% \r",
      "python-3.7.5         | #####3     |  53% \r",
      "python-3.7.5         | #####7     |  57% \r",
      "python-3.7.5         | ######     |  61% \r",
      "python-3.7.5         | ######5    |  65% \r",
      "python-3.7.5         | ######9    |  69% \r",
      "python-3.7.5         | #######2   |  73% \r",
      "python-3.7.5         | #######7   |  77% \r",
      "python-3.7.5         | ########   |  81% \r",
      "python-3.7.5         | ########4  |  85% \r",
      "python-3.7.5         | ########8  |  89% \r",
      "python-3.7.5         | #########2 |  93% \r",
      "python-3.7.5         | #########6 |  97% \r",
      "python-3.7.5         | ########## | 100% \n",
      "\r",
      "attrs-19.3.0         |            |   0% \r",
      "attrs-19.3.0         | ####1      |  41% \r",
      "attrs-19.3.0         | ########## | 100% \n",
      "\r",
      "backcall-0.1.0       |            |   0% \r",
      "backcall-0.1.0       | ########1  |  82% \r",
      "backcall-0.1.0       | ########## | 100% \n",
      "\r",
      "certifi-2019.11.28   |            |   0% \r",
      "certifi-2019.11.28   | #          |  10% \r",
      "certifi-2019.11.28   | ########## | 100% \n",
      "\r",
      "decorator-4.4.1      |            |   0% \r",
      "decorator-4.4.1      | ########## | 100% \r",
      "decorator-4.4.1      | ########## | 100% \n",
      "\r",
      "defusedxml-0.6.0     |            |   0% \r",
      "defusedxml-0.6.0     | ########## | 100% \n",
      "\r",
      "entrypoints-0.3      |            |   0% \r",
      "entrypoints-0.3      | ########## | 100% \n",
      "\r",
      "ipython_genutils-0.2 |            |   0% \r",
      "ipython_genutils-0.2 | ####1      |  41% \r",
      "ipython_genutils-0.2 | ########## | 100% \n",
      "\r",
      "markupsafe-1.1.1     |            |   0% \r",
      "markupsafe-1.1.1     | #####4     |  54% \r",
      "markupsafe-1.1.1     | ########## | 100% \n",
      "\r",
      "mistune-0.8.4        |            |   0% \r",
      "mistune-0.8.4        | ##9        |  30% \r",
      "mistune-0.8.4        | ########## | 100% \n",
      "\r",
      "more-itertools-8.0.2 |            |   0% \r",
      "more-itertools-8.0.2 | ####3      |  43% \r",
      "more-itertools-8.0.2 | ########## | 100% \n",
      "\r",
      "ninja-1.9.0          |            |   0% \r",
      "ninja-1.9.0          |            |   1% \r",
      "ninja-1.9.0          | ########## | 100% \r",
      "ninja-1.9.0          | ########## | 100% \n",
      "\r",
      "olefile-0.46         |            |   0% \r",
      "olefile-0.46         | ########## | 100% \n",
      "\r",
      "pandocfilters-1.4.2  |            |   0% \r",
      "pandocfilters-1.4.2  | ########## | 100% \r",
      "pandocfilters-1.4.2  | ########## | 100% \n",
      "\r",
      "parso-0.5.2          |            |   0% \r",
      "parso-0.5.2          | ##3        |  23% \r",
      "parso-0.5.2          | ########## | 100% \n",
      "\r",
      "pickleshare-0.7.5    |            |   0% \r",
      "pickleshare-0.7.5    | ########## | 100% \r",
      "pickleshare-0.7.5    | ########## | 100% \n",
      "\r",
      "prometheus_client-0. |            |   0% \r",
      "prometheus_client-0. | ###8       |  38% \r",
      "prometheus_client-0. | ########## | 100% \n",
      "\r",
      "ptyprocess-0.6.0     |            |   0% \r",
      "ptyprocess-0.6.0     | #######    |  71% \r",
      "ptyprocess-0.6.0     | ########## | 100% \n",
      "\r",
      "pycparser-2.19       |            |   0% \r",
      "pycparser-2.19       | #8         |  18% \r",
      "pycparser-2.19       | ########## | 100% \n",
      "\r",
      "pytz-2019.3          |            |   0% \r",
      "pytz-2019.3          | 6          |   7% \r",
      "pytz-2019.3          | ########## | 100% \r",
      "pytz-2019.3          | ########## | 100% \n",
      "\r",
      "pyzmq-18.1.0         |            |   0% \r",
      "pyzmq-18.1.0         | 3          |   3% \r",
      "pyzmq-18.1.0         | ########## | 100% \r",
      "pyzmq-18.1.0         | ########## | 100% \n",
      "\r",
      "qt-5.9.7             |            |   0% \r",
      "qt-5.9.7             | 1          |   2% \r",
      "qt-5.9.7             | #8         |  19% \r",
      "qt-5.9.7             | ###6       |  37% \r",
      "qt-5.9.7             | #####4     |  54% \r",
      "qt-5.9.7             | ######9    |  70% \r",
      "qt-5.9.7             | ########6  |  86% \r",
      "qt-5.9.7             | ########## | 100% \n",
      "\r",
      "send2trash-1.5.0     |            |   0% \r",
      "send2trash-1.5.0     | ########## | 100% \r",
      "send2trash-1.5.0     | ########## | 100% \n",
      "\r",
      "sip-4.19.13          |            |   0% \r",
      "sip-4.19.13          | 5          |   5% \r",
      "sip-4.19.13          | ########## | 100% \n",
      "\r",
      "six-1.13.0           |            |   0% \r",
      "six-1.13.0           | ######     |  60% \r",
      "six-1.13.0           | ########## | 100% \n",
      "\r",
      "testpath-0.4.4       |            |   0% \r",
      "testpath-0.4.4       | ########## | 100% \n",
      "\r",
      "tornado-6.0.3        |            |   0% \r",
      "tornado-6.0.3        | ########## | 100% \r",
      "tornado-6.0.3        | ########## | 100% \n",
      "\r",
      "wcwidth-0.1.7        |            |   0% \r",
      "wcwidth-0.1.7        | ######9    |  70% \r",
      "wcwidth-0.1.7        | ########## | 100% \n",
      "\r",
      "webencodings-0.5.1   |            |   0% \r",
      "webencodings-0.5.1   | ########## | 100% \n",
      "\r",
      "cffi-1.13.2          |            |   0% \r",
      "cffi-1.13.2          | 7          |   7% \r",
      "cffi-1.13.2          | #######8   |  78% \r",
      "cffi-1.13.2          | ########## | 100% \n",
      "\r",
      "jedi-0.15.1          |            |   0% \r",
      "jedi-0.15.1          | 2          |   2% \r",
      "jedi-0.15.1          | ########## | 100% \r",
      "jedi-0.15.1          | ########## | 100% \n",
      "\r",
      "mkl-service-2.3.0    |            |   0% \r",
      "mkl-service-2.3.0    | 7          |   8% \r",
      "mkl-service-2.3.0    | ########## | 100% \n",
      "\r",
      "networkx-1.11        |            |   0% \r",
      "networkx-1.11        | 1          |   1% \r",
      "networkx-1.11        | ########## | 100% \r",
      "networkx-1.11        | ########## | 100% \n",
      "\r",
      "pexpect-4.7.0        |            |   0% \r",
      "pexpect-4.7.0        | #9         |  19% \r",
      "pexpect-4.7.0        | ########## | 100% \n",
      "\r",
      "pillow-6.2.1         |            |   0% \r",
      "pillow-6.2.1         | 2          |   2% \r",
      "pillow-6.2.1         | ########## | 100% \r",
      "pillow-6.2.1         | ########## | 100% \n",
      "\r",
      "pyqt-5.9.2           |            |   0% \r",
      "pyqt-5.9.2           | ########9  |  90% \r",
      "pyqt-5.9.2           | ########## | 100% \n",
      "\r",
      "pyrsistent-0.15.6    |            |   0% \r",
      "pyrsistent-0.15.6    | #7         |  17% \r",
      "pyrsistent-0.15.6    | ########## | 100% \n",
      "\r",
      "python-dateutil-2.8. |            |   0% \r",
      "python-dateutil-2.8. | ########## | 100% \n",
      "\r",
      "setuptools-42.0.2    |            |   0% \r",
      "setuptools-42.0.2    | 2          |   2% \r",
      "setuptools-42.0.2    | ########## | 100% \r",
      "setuptools-42.0.2    | ########## | 100% \n",
      "\r",
      "terminado-0.8.3      |            |   0% \r",
      "terminado-0.8.3      | ######4    |  64% \r",
      "terminado-0.8.3      | ########## | 100% \n",
      "\r",
      "traitlets-4.3.3      |            |   0% \r",
      "traitlets-4.3.3      | #1         |  12% \r",
      "traitlets-4.3.3      | ########## | 100% \n",
      "\r",
      "zipp-0.6.0           |            |   0% \r",
      "zipp-0.6.0           | ########## | 100% \r",
      "zipp-0.6.0           | ########## | 100% \n",
      "\r",
      "bleach-3.1.0         |            |   0% \r",
      "bleach-3.1.0         | #4         |  14% \r",
      "bleach-3.1.0         | ########## | 100% \n",
      "\r",
      "importlib_metadata-1 |            |   0% \r",
      "importlib_metadata-1 | ###4       |  35% \r",
      "importlib_metadata-1 | ########## | 100% \n",
      "\r",
      "jinja2-2.10.3        |            |   0% \r",
      "jinja2-2.10.3        | #6         |  17% \r",
      "jinja2-2.10.3        | ########## | 100% \n",
      "\r",
      "jupyter_core-4.6.1   |            |   0% \r",
      "jupyter_core-4.6.1   | ##1        |  22% \r",
      "jupyter_core-4.6.1   | ########## | 100% \n",
      "\r",
      "numpy-base-1.17.4    |            |   0% \r",
      "numpy-base-1.17.4    |            |   0% \r",
      "numpy-base-1.17.4    | #9         |  19% \r",
      "numpy-base-1.17.4    | #####7     |  58% \r",
      "numpy-base-1.17.4    | ########## | 100% \r",
      "numpy-base-1.17.4    | ########## | 100% \n",
      "\r",
      "pygments-2.5.2       |            |   0% \r",
      "pygments-2.5.2       | 2          |   2% \r",
      "pygments-2.5.2       | ########3  |  83% \r",
      "pygments-2.5.2       | ########## | 100% \n",
      "\r",
      "wheel-0.33.6         |            |   0% \r",
      "wheel-0.33.6         | ###9       |  40% \r",
      "wheel-0.33.6         | ########## | 100% \n",
      "\r",
      "jsonschema-3.2.0     |            |   0% \r",
      "jsonschema-3.2.0     | #7         |  17% \r",
      "jsonschema-3.2.0     | ########## | 100% \n",
      "\r",
      "jupyter_client-5.3.4 |            |   0% \r",
      "jupyter_client-5.3.4 | #1         |  12% \r",
      "jupyter_client-5.3.4 | ########## | 100% \n",
      "\r",
      "pip-19.3.1           |            |   0% \r",
      "pip-19.3.1           |            |   1% \r",
      "pip-19.3.1           | ########7  |  88% \r",
      "pip-19.3.1           | ########## | 100% \n",
      "\r",
      "prompt_toolkit-3.0.2 |            |   0% \r",
      "prompt_toolkit-3.0.2 | 6          |   7% \r",
      "prompt_toolkit-3.0.2 | ########## | 100% \r",
      "prompt_toolkit-3.0.2 | ########## | 100% \n",
      "\r",
      "ipython-7.10.2       |            |   0% \r",
      "ipython-7.10.2       | 1          |   1% \r",
      "ipython-7.10.2       | ########## | 100% \r",
      "ipython-7.10.2       | ########## | 100% \n",
      "\r",
      "nbformat-4.4.0       |            |   0% \r",
      "nbformat-4.4.0       | #1         |  11% \r",
      "nbformat-4.4.0       | ########## | 100% \n",
      "\r",
      "ipykernel-5.1.3      |            |   0% \r",
      "ipykernel-5.1.3      | 9          |  10% \r",
      "ipykernel-5.1.3      | ########## | 100% \n",
      "\r",
      "nbconvert-5.6.1      |            |   0% \r",
      "nbconvert-5.6.1      | 3          |   3% \r",
      "nbconvert-5.6.1      | ########## | 100% \r",
      "nbconvert-5.6.1      | ########## | 100% \n",
      "\r",
      "jupyter_console-5.2. |            |   0% \r",
      "jupyter_console-5.2. | ####4      |  45% \r",
      "jupyter_console-5.2. | ########## | 100% \n",
      "\r",
      "notebook-6.0.2       |            |   0% \r",
      "notebook-6.0.2       |            |   0% \r",
      "notebook-6.0.2       | ##2        |  23% \r",
      "notebook-6.0.2       | ######     |  60% \r",
      "notebook-6.0.2       | ########## | 100% \r",
      "notebook-6.0.2       | ########## | 100% \n",
      "\r",
      "qtconsole-4.6.0      |            |   0% \r",
      "qtconsole-4.6.0      | #6         |  17% \r",
      "qtconsole-4.6.0      | ########## | 100% \n",
      "\r",
      "widgetsnbextension-3 |            |   0% \r",
      "widgetsnbextension-3 | ########## | 100% \r",
      "widgetsnbextension-3 | ########## | 100% \n",
      "\r",
      "ipywidgets-7.5.1     |            |   0% \r",
      "ipywidgets-7.5.1     | #4         |  15% \r",
      "ipywidgets-7.5.1     | ########## | 100% \n",
      "\r",
      "jupyter-1.0.0        |            |   0% \r",
      "jupyter-1.0.0        | ########## | 100% \r",
      "jupyter-1.0.0        | ########## | 100% \n",
      "\r",
      "faiss-gpu-1.6.0      |            |   0% \r",
      "faiss-gpu-1.6.0      |            |   0% \r",
      "faiss-gpu-1.6.0      |            |   0% \r",
      "faiss-gpu-1.6.0      |            |   1% \r",
      "faiss-gpu-1.6.0      | 2          |   3% \r",
      "faiss-gpu-1.6.0      | 8          |   8% \r",
      "faiss-gpu-1.6.0      | #4         |  15% \r",
      "faiss-gpu-1.6.0      | ##1        |  21% \r",
      "faiss-gpu-1.6.0      | ##9        |  29% \r",
      "faiss-gpu-1.6.0      | ###7       |  38% \r",
      "faiss-gpu-1.6.0      | ####4      |  45% \r",
      "faiss-gpu-1.6.0      | #####3     |  54% \r",
      "faiss-gpu-1.6.0      | ######     |  61% \r",
      "faiss-gpu-1.6.0      | ######8    |  69% \r",
      "faiss-gpu-1.6.0      | #######7   |  78% \r",
      "faiss-gpu-1.6.0      | ########6  |  86% \r",
      "faiss-gpu-1.6.0      | #########5 |  95% \r",
      "faiss-gpu-1.6.0      | ########## | 100% \n",
      "\r",
      "mkl_fft-1.0.15       |            |   0% \r",
      "mkl_fft-1.0.15       | 9          |   9% \r",
      "mkl_fft-1.0.15       | ########## | 100% \n",
      "\r",
      "mkl_random-1.1.0     |            |   0% \r",
      "mkl_random-1.1.0     | ########## | 100% \n",
      "\r",
      "numpy-1.17.4         |            |   0% \r",
      "numpy-1.17.4         | ########## | 100% \r",
      "numpy-1.17.4         | ########## | 100% \n",
      "\r",
      "pandas-0.25.3        |            |   0% \r",
      "pandas-0.25.3        |            |   0% \r",
      "pandas-0.25.3        | #5         |  16% \r",
      "pandas-0.25.3        | ###4       |  34% \r",
      "pandas-0.25.3        | ####6      |  47% \r",
      "pandas-0.25.3        | #####9     |  59% \r",
      "pandas-0.25.3        | #######2   |  72% \r",
      "pandas-0.25.3        | ########4  |  84% \r",
      "pandas-0.25.3        | #########5 |  96% \r",
      "pandas-0.25.3        | ########## | 100% \n",
      "\r",
      "pytorch-1.3.1        |            |   0% \r",
      "pytorch-1.3.1        |            |   0% \r",
      "pytorch-1.3.1        |            |   0% \r",
      "pytorch-1.3.1        |            |   0% \r",
      "pytorch-1.3.1        |            |   0% \r",
      "pytorch-1.3.1        | 1          |   1% \r",
      "pytorch-1.3.1        | 2          |   3% \r",
      "pytorch-1.3.1        | 3          |   4% \r",
      "pytorch-1.3.1        | 5          |   5% \r",
      "pytorch-1.3.1        | 6          |   7% \r",
      "pytorch-1.3.1        | 7          |   8% \r",
      "pytorch-1.3.1        | 9          |   9% \r",
      "pytorch-1.3.1        | #          |  10% \r",
      "pytorch-1.3.1        | #1         |  12% \r",
      "pytorch-1.3.1        | #2         |  13% \r",
      "pytorch-1.3.1        | #3         |  14% \r",
      "pytorch-1.3.1        | #4         |  15% \r",
      "pytorch-1.3.1        | #6         |  16% \r",
      "pytorch-1.3.1        | #7         |  17% \r",
      "pytorch-1.3.1        | #8         |  19% \r",
      "pytorch-1.3.1        | #9         |  20% \r",
      "pytorch-1.3.1        | ##         |  21% \r",
      "pytorch-1.3.1        | ##1        |  21% \r",
      "pytorch-1.3.1        | ##2        |  22% \r",
      "pytorch-1.3.1        | ##3        |  24% \r",
      "pytorch-1.3.1        | ##4        |  25% \r",
      "pytorch-1.3.1        | ##6        |  26% \r",
      "pytorch-1.3.1        | ##7        |  27% \r",
      "pytorch-1.3.1        | ##8        |  28% \r",
      "pytorch-1.3.1        | ##9        |  30% \r",
      "pytorch-1.3.1        | ###        |  31% \r",
      "pytorch-1.3.1        | ###2       |  32% \r",
      "pytorch-1.3.1        | ###3       |  34% \r",
      "pytorch-1.3.1        | ###5       |  35% \r",
      "pytorch-1.3.1        | ###6       |  37% \r",
      "pytorch-1.3.1        | ###7       |  38% \r",
      "pytorch-1.3.1        | ###9       |  39% \r",
      "pytorch-1.3.1        | ####       |  41% \r",
      "pytorch-1.3.1        | ####2      |  42% \r",
      "pytorch-1.3.1        | ####3      |  44% \r",
      "pytorch-1.3.1        | ####5      |  45% \r",
      "pytorch-1.3.1        | ####6      |  46% \r",
      "pytorch-1.3.1        | ####7      |  48% \r",
      "pytorch-1.3.1        | ####9      |  49% \r",
      "pytorch-1.3.1        | ####9      |  50% \r",
      "pytorch-1.3.1        | #####1     |  51% \r",
      "pytorch-1.3.1        | #####2     |  52% \r",
      "pytorch-1.3.1        | #####3     |  54% \r",
      "pytorch-1.3.1        | #####4     |  55% \r",
      "pytorch-1.3.1        | #####5     |  56% \r",
      "pytorch-1.3.1        | #####7     |  57% \r",
      "pytorch-1.3.1        | #####8     |  59% \r",
      "pytorch-1.3.1        | ######     |  60% \r",
      "pytorch-1.3.1        | ######1    |  61% \r",
      "pytorch-1.3.1        | ######2    |  63% \r",
      "pytorch-1.3.1        | ######3    |  64% \r",
      "pytorch-1.3.1        | ######4    |  65% \r",
      "pytorch-1.3.1        | ######6    |  66% \r",
      "pytorch-1.3.1        | ######7    |  67% \r",
      "pytorch-1.3.1        | ######8    |  68% \r",
      "pytorch-1.3.1        | ######8    |  69% \r",
      "pytorch-1.3.1        | ######9    |  69% \r",
      "pytorch-1.3.1        | #######    |  70% \r",
      "pytorch-1.3.1        | #######1   |  71% \r",
      "pytorch-1.3.1        | #######2   |  73% \r",
      "pytorch-1.3.1        | #######4   |  74% \r",
      "pytorch-1.3.1        | #######5   |  76% \r",
      "pytorch-1.3.1        | #######6   |  77% \r",
      "pytorch-1.3.1        | #######8   |  78% \r",
      "pytorch-1.3.1        | #######9   |  79% \r",
      "pytorch-1.3.1        | ########   |  80% \r",
      "pytorch-1.3.1        | ########1  |  81% \r",
      "pytorch-1.3.1        | ########2  |  83% \r",
      "pytorch-1.3.1        | ########4  |  84% \r",
      "pytorch-1.3.1        | ########5  |  86% \r",
      "pytorch-1.3.1        | ########6  |  87% \r",
      "pytorch-1.3.1        | ########8  |  88% \r",
      "pytorch-1.3.1        | ########9  |  90% \r",
      "pytorch-1.3.1        | #########1 |  91% \r",
      "pytorch-1.3.1        | #########2 |  92% \r",
      "pytorch-1.3.1        | #########3 |  94% \r",
      "pytorch-1.3.1        | #########5 |  95% \r",
      "pytorch-1.3.1        | #########6 |  97% \r",
      "pytorch-1.3.1        | #########8 |  98% \r",
      "pytorch-1.3.1        | #########9 |  99% \r",
      "pytorch-1.3.1        | ########## | 100% \n",
      "\r",
      "torchvision-0.4.2    |            |   0% \r",
      "torchvision-0.4.2    |            |   0% \r",
      "torchvision-0.4.2    |            |   1% \r",
      "torchvision-0.4.2    | 2          |   3% \r",
      "torchvision-0.4.2    | #1         |  12% \r",
      "torchvision-0.4.2    | ###8       |  39% \r",
      "torchvision-0.4.2    | ######7    |  67% \r",
      "torchvision-0.4.2    | #########6 |  96% \r",
      "torchvision-0.4.2    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "no change     /usr/local/condabin/conda\n",
      "no change     /usr/local/bin/conda\n",
      "no change     /usr/local/bin/conda-env\n",
      "no change     /usr/local/bin/activate\n",
      "no change     /usr/local/bin/deactivate\n",
      "no change     /usr/local/etc/profile.d/conda.sh\n",
      "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
      "no change     /usr/local/shell/condabin/Conda.psm1\n",
      "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
      "no change     /usr/local/lib/python3.7/site-packages/xontrib/conda.xsh\n",
      "no change     /usr/local/etc/profile.d/conda.csh\n",
      "modified      /root/.bashrc\n",
      "\n",
      "==> For changes to take effect, close and re-open your current shell. <==\n",
      "\n",
      "Processing /content/xtreme/third_party/transformers\n",
      "Requirement already satisfied: numpy in /usr/local/envs/xtreme/lib/python3.7/site-packages (from transformers==2.3.0) (1.17.4)\n",
      "Collecting tokenizers==0.0.11\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/cb/3e8902d528538972873d0e9e4e47a31d1849a98e057009e9d383637c96fb/tokenizers-0.0.11-cp37-cp37m-manylinux1_x86_64.whl (4.7MB)\n",
      "Collecting boto3\n",
      "  Downloading https://files.pythonhosted.org/packages/56/43/0d324a61309c32bda58b5ecaf838ab7af2395ce266729214a7f052771436/boto3-1.18.7-py3-none-any.whl (131kB)\n",
      "Collecting filelock\n",
      "  Downloading https://files.pythonhosted.org/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl\n",
      "Collecting requests\n",
      "  Downloading https://files.pythonhosted.org/packages/92/96/144f70b972a9c0eabbd4391ef93ccd49d0f2747f4f6a2a2738e99e5adc65/requests-2.26.0-py2.py3-none-any.whl (62kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/ec/f8ff3ccfc4e59ce619a66a0bf29dc3b49c2e8c07de29d572e191c006eaa2/tqdm-4.61.2-py2.py3-none-any.whl (76kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/f4/2f5fd1d2b7d383d08128d2f79667ab1568f200e21b701eafca7c0075b8cf/regex-2021.7.6-cp37-cp37m-manylinux2014_x86_64.whl (721kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
      "Collecting sacremoses\n",
      "  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "Collecting botocore<1.22.0,>=1.21.7\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/6d/5235634806b8fd36f78ba114656d887d78401ab85982c569b41cddff5a9c/botocore-1.21.7-py3-none-any.whl (7.7MB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/84/fc3717a7b7f0f6bb08af593127171f08e3e0087c197922da09c01bfe7c3a/s3transfer-0.5.0-py3-none-any.whl (79kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/64/43575537846896abac0b15c3e5ac678d787a4021e906703f1766bfb8ea11/urllib3-1.26.6-py2.py3-none-any.whl (138kB)\n",
      "Collecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/77/ff688d1504cdc4db2a938e2b7b9adee5dd52e34efbd2431051efc9984de9/idna-3.2-py3-none-any.whl (59kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from requests->transformers==2.3.0) (2019.11.28)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/1d/e6ce112f7237fc746e632e1cbdc24890cad95505c6cd4b711f4fd17f4735/charset_normalizer-2.0.3-py3-none-any.whl\n",
      "Collecting click\n",
      "  Downloading https://files.pythonhosted.org/packages/76/0a/b6c5f311e32aeb3b406e03c079ade51e905ea630fc19d1262a46249c1c86/click-8.0.1-py3-none-any.whl (97kB)\n",
      "Collecting joblib\n",
      "  Downloading https://files.pythonhosted.org/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl (303kB)\n",
      "Requirement already satisfied: six in /usr/local/envs/xtreme/lib/python3.7/site-packages (from sacremoses->transformers==2.3.0) (1.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from botocore<1.22.0,>=1.21.7->boto3->transformers==2.3.0) (2.8.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/envs/xtreme/lib/python3.7/site-packages (from click->sacremoses->transformers==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->sacremoses->transformers==2.3.0) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /usr/local/envs/xtreme/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->click->sacremoses->transformers==2.3.0) (8.0.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (setup.py): started\n",
      "  Building wheel for transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-2.3.0-cp37-none-any.whl size=467057 sha256=0c0ad8af991a73ce598f91c3a05061ab130f5a32d7ad662a6ea33ce63744a178\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xa6b2gx4/wheels/1c/36/4f/b33855cff460e61bb688737629e0db864677dc029ea1d8d1d6\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, urllib3, jmespath, botocore, s3transfer, boto3, filelock, idna, charset-normalizer, requests, tqdm, regex, sentencepiece, click, joblib, sacremoses, transformers\n",
      "Successfully installed boto3-1.18.7 botocore-1.21.7 charset-normalizer-2.0.3 click-8.0.1 filelock-3.0.12 idna-3.2 jmespath-0.10.0 joblib-1.0.1 regex-2021.7.6 requests-2.26.0 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.0.11 tqdm-4.61.2 transformers-2.3.0 urllib3-1.26.6\n",
      "Collecting seqeval\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from seqeval) (1.17.4)\n",
      "Collecting scikit-learn>=0.21.3\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/e8/c216b9b60cbba4642d3ca1bae7a53daa0c24426f662e0e3ce3dc7f6caeaa/threadpoolctl-2.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/85/b00f13b52d079b5625e1a12330fc6453c947a482ff667a907c7bc60ed220/scipy-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5MB)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16171 sha256=6e1fcc40115394940f3d24aa360cf71e9cd3909f8656c4950d1a0969c7c95aa1\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
      "Successfully built seqeval\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, seqeval\n",
      "Successfully installed scikit-learn-0.24.2 scipy-1.7.0 seqeval-1.2.2 threadpoolctl-2.2.0\n",
      "Collecting tensorboardx\n",
      "  Downloading https://files.pythonhosted.org/packages/99/0b/a26bbe92667c549d39c40b80c5ddec638fbae9521f04aeef26560e07e504/tensorboardX-2.4-py2.py3-none-any.whl (124kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/53/ddcef00219f2a3c863b24288e24a20c3070bd086a1e77706f22994a7f6db/protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0MB)\n",
      "Requirement already satisfied: numpy in /usr/local/envs/xtreme/lib/python3.7/site-packages (from tensorboardx) (1.17.4)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorboardx) (1.13.0)\n",
      "Installing collected packages: protobuf, tensorboardx\n",
      "Successfully installed protobuf-3.17.3 tensorboardx-2.4\n",
      "Requirement already satisfied: tqdm in /usr/local/envs/xtreme/lib/python3.7/site-packages (4.61.2)\n",
      "Requirement already satisfied: sacremoses in /usr/local/envs/xtreme/lib/python3.7/site-packages (0.0.45)\n",
      "Requirement already satisfied: six in /usr/local/envs/xtreme/lib/python3.7/site-packages (from sacremoses) (1.13.0)\n",
      "Requirement already satisfied: joblib in /usr/local/envs/xtreme/lib/python3.7/site-packages (from sacremoses) (1.0.1)\n",
      "Requirement already satisfied: regex in /usr/local/envs/xtreme/lib/python3.7/site-packages (from sacremoses) (2021.7.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/envs/xtreme/lib/python3.7/site-packages (from sacremoses) (4.61.2)\n",
      "Requirement already satisfied: click in /usr/local/envs/xtreme/lib/python3.7/site-packages (from sacremoses) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/envs/xtreme/lib/python3.7/site-packages (from click->sacremoses) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->sacremoses) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /usr/local/envs/xtreme/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->click->sacremoses) (8.0.2)\n",
      "Collecting pythainlp\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/e7/837dd9ab52fac889af830dc094a1598251f70004a2f1707ab0ff8dc0f63a/pythainlp-2.3.1-py3-none-any.whl (11.0MB)\n",
      "Collecting python-crfsuite>=0.9.6\n",
      "  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from pythainlp) (2.26.0)\n",
      "Collecting tinydb>=3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/9c/137dd3aac4e55da4b4c6b34c4a1b729a0aee08350d03bab205472341c3bf/tinydb-4.5.1-py3-none-any.whl\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/envs/xtreme/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp) (2.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/envs/xtreme/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/xtreme/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp) (2019.11.28)\n",
      "Collecting typing-extensions<4.0.0,>=3.10.0; python_version <= \"3.7\"\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/35/6c4fff5ab443b57116cb1aad46421fb719bed2825664e8fe77d66d99bcbc/typing_extensions-3.10.0.0-py3-none-any.whl\n",
      "Installing collected packages: python-crfsuite, typing-extensions, tinydb, pythainlp\n",
      "Successfully installed pythainlp-2.3.1 python-crfsuite-0.9.7 tinydb-4.5.1 typing-extensions-3.10.0.0\n",
      "Collecting jieba\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2MB)\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-cp37-none-any.whl size=19314477 sha256=01bd142fbddc9c3405eeb1ea20a3091fc104f28016a632c87689b2ee85176934\n",
      "  Stored in directory: /root/.cache/pip/wheels/af/e4/8e/5fdd61a6b45032936b8f9ae2044ab33e61577950ce8e0dec29\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "Collecting kytea\n",
      "  Downloading https://files.pythonhosted.org/packages/32/e7/111ef22133a1316dd85aa9266bfffbaddb36a09e463edc1f80dd7023a771/kytea-0.1.5-cp37-cp37m-manylinux2010_x86_64.whl (5.2MB)\n",
      "Installing collected packages: kytea\n",
      "Successfully installed kytea-0.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: cd: drive/MyDrive/: No such file or directory\n",
      "+ cd /content/xtreme/third_party\n",
      "+ rm -rf transformers\n",
      "+ git clone https://github.com/huggingface/transformers\n",
      "Cloning into 'transformers'...\n",
      "+ cd transformers\n",
      "+ git checkout cefd51c50cc08be8146c1151544495968ce8f2ad --force\n",
      "Note: checking out 'cefd51c50cc08be8146c1151544495968ce8f2ad'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by performing another checkout.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -b with the checkout command again. Example:\n",
      "\n",
      "  git checkout -b <new-branch-name>\n",
      "\n",
      "HEAD is now at cefd51c50 Fix glue processor failing on tf datasets\n",
      "+ pip install .\n",
      "+ cd /content/xtreme/third_party\n",
      "+ pip install seqeval\n",
      "+ pip install tensorboardx\n",
      "+ pip install tqdm\n",
      "+ pip install sacremoses\n",
      "+ pip install pythainlp\n",
      "+ pip install jieba\n",
      "+ pip install kytea\n"
     ]
    }
   ],
   "source": [
    "# First, we need to install required dependencies. Instead of running their install_tools.sh, run this cell, which has a few minor modifications. This may take a few minutes to run.\n",
    "\n",
    "%%bash\n",
    "cd drive/MyDrive/ # Optional but recommended\n",
    "cd xtreme/\n",
    "# Copyright 2020 Google and DeepMind.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "set +eux  # for easier debugging\n",
    "\n",
    "REPO=$PWD\n",
    "LIB=$REPO/third_party\n",
    "mkdir -p $LIB\n",
    "\n",
    "# install conda env\n",
    "conda create --yes --name xtreme --file conda-env.txt \n",
    "conda init bash\n",
    "source activate xtreme\n",
    "set -eux\n",
    "\n",
    "# install latest transformer\n",
    "cd $LIB\n",
    "rm -rf transformers\n",
    "git clone https://github.com/huggingface/transformers\n",
    "cd transformers\n",
    "git checkout cefd51c50cc08be8146c1151544495968ce8f2ad --force\n",
    "pip install .\n",
    "cd $LIB\n",
    "\n",
    "pip install seqeval\n",
    "pip install tensorboardx\n",
    "pip install tqdm\n",
    "\n",
    "# install XLM tokenizer\n",
    "pip install sacremoses\n",
    "pip install pythainlp\n",
    "pip install jieba\n",
    "\n",
    "#git clone https://github.com/neubig/kytea.git && cd kytea\n",
    "#./configure --prefix=${CONDA_PREFIX}\n",
    "#make && make install\n",
    "pip install kytea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4DVHoBlCuAa"
   },
   "source": [
    "## Training\n",
    "\n",
    "Although this codebase can be used for many varieties of training methods and experiments, we will only train a straightforward baseline. We will create a monolingual Hindi QA model. We encourage you to read and experiment with the Xtreme codebase, and also with other repos. Some promising avenues:\n",
    "\n",
    "* Train model on both Hindi and Tamil ChAII data,\n",
    "* Multi-task learning with Xtreme,\n",
    "* Annotate your own data into a QA format and augment training,\n",
    "* Zero-shot transfer learning\n",
    "\n",
    "The cells below do the following:\n",
    "\n",
    "1. Convert the given ChAII data (from competition) to QA (SQuAD) format, split into train and dev sets.\n",
    "2. Finetune mBERT (bert-base-multilingual-cased) on the ChAII data.\n",
    "3. Save the model and dev predictions into GDrive for evaluation later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwbfBnSXDcQk"
   },
   "source": [
    "### Data conversion to QA format\n",
    "\n",
    "The below cell converts the ChAII data from the TyDiQA format to the SQuAD QA format, so it can be used with the Xtreme pipeline. You need to download the ChAII data from Kaggle, and either upload on your Google Drive or locally onto the Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "aE9wX7A8D-me",
    "outputId": "38ff7707-6fd1-4eb7-88d9-211643eb2df7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "748it [00:01, 559.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TyDiQA format:\n",
      "{'paragraphs': [{'context': '        '\n",
      "                            '       [1]  '\n",
      "                            '        , '\n",
      "                            '     -     '\n",
      "                            '          '\n",
      "                            '          '\n",
      "                            '         '\n",
      "                            '         '\n",
      "                            '            '\n",
      "                            '            '\n",
      "                            '          '\n",
      "                            '     ,     '\n",
      "                            '         '\n",
      "                            '          '\n",
      "                            '       '\n",
      "                            '\\n'\n",
      "                            '         '\n",
      "                            '         '\n",
      "                            '    ,      '\n",
      "                            '         '\n",
      "                            '          '\n",
      "                            '          '\n",
      "                            '        '\n",
      "                            '         '\n",
      "                            '         '\n",
      "                            '          '\n",
      "                            '         '\n",
      "                            '          '\n",
      "                            '           '\n",
      "                            '        '\n",
      "                            '[2]\\n'\n",
      "                            '        '\n",
      "                            '      ,  '\n",
      "                            ', ,       '\n",
      "                            '          '\n",
      "                            '         '\n",
      "                            '      , '\n",
      "                            ' ,      '\n",
      "                            '     ,  '\n",
      "                            ',        '\n",
      "                            '        '\n",
      "                            '       \\n'\n",
      "                            '\"           '\n",
      "                            '          '\n",
      "                            '    \"by siddharth lodha '\n",
      "                            'ratlai.\\n'\n",
      "                            '  \\n'\n",
      "                            '\\n'\n",
      "                            ':\\n'\n",
      "                            ':\\n'\n",
      "                            ':   ',\n",
      "                 'qas': [{'answers': [{'answer_start': 935,\n",
      "                                       'text': ' '}],\n",
      "                          'id': 'hindi-0',\n",
      "                          'question': '        '\n",
      "                                      '        '\n",
      "                                      '  ?'}]}],\n",
      " 'title': ''}\n",
      "time: 1.66 s (started: 2021-07-30 04:45:13 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Convert TyDiQA format to a QA format\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import functools\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_path = \"/root/mount/dataset\"\n",
    "json_dicts = []\n",
    "\n",
    "with open(os.path.join(data_path,\"chaii_tydiqa_answer_labeling_hi_train.jsonl\"),'r') as f:\n",
    "  for line in tqdm(f):\n",
    "    json_dict = json.loads(line)\n",
    "    json_dicts.append(json_dict)\n",
    "\n",
    "print(\"TyDiQA format:\")\n",
    "pprint(json_dicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hf6zv9YfJD5D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of datapoints: 748\n",
      "time: 3.85 ms (started: 2021-07-30 04:45:19 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of datapoints: %d\" % len(json_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XN5l8MNZJHy1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA (SQuAD) format:\n",
      "{'title': '', 'paragraphs': [{'context': '               [1]          ,      -                                                                                  ,                               \\n                      ,                                                                                                             [2]\\n              ,  , ,                                ,  ,           ,  ,                       \\n\"                         \"by siddharth lodha ratlai.\\n  \\n\\n:\\n:\\n:   ', 'qas': [{'question': '                  ?', 'id': 'hindi-0', 'answers': [{'text': ' ', 'answer_start': 935}]}]}]}\n",
      "time: 18.5 ms (started: 2021-07-30 04:45:30 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Split datapoints language-wise and into QA format\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "def byte_str(text):\n",
    "  return text.encode(\"utf-8\")\n",
    "\n",
    "def byte_len(text):\n",
    "  # Python 3 encodes text as character sequences, not byte sequences\n",
    "  # (like Python 2).\n",
    "  return len(byte_str(text))\n",
    "\n",
    "def byte_slice(text, start, end, errors=\"replace\"):\n",
    "  # Python 3 encodes text as character sequences, not byte sequences\n",
    "  # (like Python 2).\n",
    "  return byte_str(text)[start:end].decode(\"utf-8\", errors=errors)\n",
    "\n",
    "def convert_to_qa_format(tydi_json):\n",
    "  answer = {}\n",
    "  for annotation in tydi_json[\"annotations\"]:\n",
    "    minimal_answer = annotation[\"minimal_answer\"]\n",
    "    if minimal_answer[\"plaintext_start_byte\"] != -1 and minimal_answer[\"plaintext_end_byte\"] != -1:\n",
    "      answer[\"text\"] = byte_slice(tydi_json[\"document_plaintext\"],minimal_answer[\"plaintext_start_byte\"],minimal_answer[\"plaintext_end_byte\"])\n",
    "      answer[\"answer_start\"] = [m.start() for m in re.finditer(answer[\"text\"],tydi_json[\"document_plaintext\"])][0]\n",
    "      break\n",
    "  if answer == {}:\n",
    "    return {}\n",
    "  \n",
    "  qa_json = {\n",
    "      \"title\" : tydi_json[\"document_title\"],\n",
    "      \"paragraphs\" : [\n",
    "                      {\n",
    "                          \"context\": tydi_json[\"document_plaintext\"],\n",
    "                          \"qas\" : [\n",
    "                                   {\n",
    "                                    \"question\" : tydi_json[\"question_text\"],\n",
    "                                    \"id\" : tydi_json[\"language\"] + '-' + str(tydi_json[\"example_id\"]),\n",
    "                                    \"answers\" : [answer],\n",
    "                                   }\n",
    "                          ]\n",
    "                      }\n",
    "      ],\n",
    "  }\n",
    "\n",
    "  return qa_json\n",
    "\n",
    "  \n",
    "language_list = [\n",
    "       'tamil',\n",
    "  ]\n",
    "\n",
    "\n",
    "qa_data = {\"data\":[], \"version\":f\"TyDiQA_chaii_hi\"}\n",
    "for json_dict in json_dicts:\n",
    "#   if json_dict[\"language\"] in language_list:\n",
    "#     qa_datapoint = convert_to_qa_format(json_dict)\n",
    "#     if qa_datapoint != {}:\n",
    "#       qa_data[\"data\"].append(qa_datapoint)\n",
    "    qa_data['data'].append(json_dict)\n",
    "\n",
    "print(\"QA (SQuAD) format:\")\n",
    "print(qa_data[\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "j5se7aK7JoGM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 598\n",
      "Dev data size: 150\n",
      "time: 1.81 s (started: 2021-07-30 04:45:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into train and dev and saving converted QA formats\n",
    "\n",
    "import random\n",
    "\n",
    "qa_data_datapoints = qa_data[\"data\"]\n",
    "random.shuffle(qa_data_datapoints)\n",
    "train_size = int(len(qa_data_datapoints)*0.8)\n",
    "train_qa_data_datapoints, dev_qa_data_datapoints = qa_data_datapoints[:train_size], qa_data_datapoints[train_size:]\n",
    "\n",
    "train_qa_data = {\"data\":train_qa_data_datapoints, \"version\":f\"TyDiQA_chaii_hi_train\"}\n",
    "dev_qa_data = {\"data\":dev_qa_data_datapoints, \"version\":f\"TyDiQA_chaii_hi_dev\"}\n",
    "\n",
    "with open(os.path.join(data_path,\"train.hi.qa.jsonl\"),'w') as f:\n",
    "  json.dump(train_qa_data,f)\n",
    "\n",
    "with open(os.path.join(data_path,\"dev.hi.qa.jsonl\"),'w') as f:\n",
    "  json.dump(dev_qa_data,f)\n",
    "\n",
    "print(\"Training data size: %d\" % len(train_qa_data_datapoints))\n",
    "print(\"Dev data size: %d\" % len(dev_qa_data_datapoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scuzryHrPzHV"
   },
   "source": [
    "The cell below is optional (we have not used it for our baseline model), but it downloads the original TyDiQA data in the QA format. You can combine it with our ChAII data and boost training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ta0K5sV8b6nk"
   },
   "outputs": [],
   "source": [
    "# Downloading the data. For baseline, we can ignore the other training datasets for other tasks, and focus on training with just TyDiQA data. \n",
    "\n",
    "%%bash\n",
    "source activate xtreme\n",
    "cd drive/MyDrive/ # Optional but recommended\n",
    "cd xtreme/\n",
    "# Copyright 2020 Google and DeepMind.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "REPO=$PWD\n",
    "DIR=$REPO/download/\n",
    "mkdir -p $DIR\n",
    "\n",
    "function download_tydiqa {\n",
    "    echo \"download tydiqa-goldp\"\n",
    "    base_dir=$DIR/tydiqa/\n",
    "    mkdir -p $base_dir && cd $base_dir\n",
    "    tydiqa_train_file=tydiqa-goldp-v1.1-train.json\n",
    "    tydiqa_dev_file=tydiqa-goldp-v1.1-dev.tgz\n",
    "    wget https://storage.googleapis.com/tydiqa/v1.1/${tydiqa_train_file} -q --show-progress\n",
    "    wget https://storage.googleapis.com/tydiqa/v1.1/${tydiqa_dev_file} -q --show-progress\n",
    "    tar -xf ${tydiqa_dev_file}\n",
    "    rm ${tydiqa_dev_file}\n",
    "    out_dir=$base_dir/tydiqa-goldp-v1.1-train\n",
    "    python $REPO/utils_preprocess.py --data_dir $base_dir --output_dir $out_dir --task tydiqa\n",
    "    mv $base_dir/$tydiqa_train_file $out_dir/\n",
    "    echo \"Successfully downloaded data at $DIR/tydiqa\" >> $DIR/download.log\n",
    "}\n",
    "\n",
    "download_tydiqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZX8uTFPfQQJR"
   },
   "source": [
    "### Training mBERT on Hindi ChAII data\n",
    "\n",
    "The below script uses the Xtreme script to train the data. Here, we need to modify the code in the folders to train it on the ChAII data. You can double click on the scripts, modify the code and change them. \n",
    "\n",
    "For the baseline, the following changes were made to the Xtreme repo code:\n",
    "\n",
    "\n",
    "1.   In ```scripts/train.sh```, an additional task called \"chaii_hi\" was added as such:\n",
    "```\n",
    "...\n",
    "elif [ $TASK == 'chaii_hi' ]; then\n",
    "  bash $REPO/scripts/train_qa.sh $MODEL chaii_hi $TASK $GPU $DATA_DIR $OUT_DIR\n",
    "...\n",
    "```\n",
    "2.   In ```scripts/train_qa.sh```, the following flags were added:\n",
    "```\n",
    "TRAIN_LANG=\"en\"\n",
    "EVAL_LANG=\"en\"\n",
    "```\n",
    "Another elif condition was added as such to modify path of data dir:\n",
    "```\n",
    "...\n",
    "elif [ $SRC == 'chaii_hi' ]; then\n",
    "  TASK_DATA_DIR=\"/content/drive/MyDrive/chaii_data\"\n",
    "  TRAIN_FILE=${TASK_DATA_DIR}/train.hi.qa.jsonl\n",
    "  PREDICT_FILE=${TASK_DATA_DIR}/dev.hi.qa.jsonl\n",
    "  TRAIN_LANG=\"hi\"\n",
    "  EVAL_LANG=\"hi\"\n",
    "...\n",
    "```\n",
    "Finally, TRAIN_LANG and EVAL_LANG replaced the hardcoded \"en\":\n",
    "```\n",
    " --weight_decay 0.0001 \\\n",
    "  --threads 8 \\\n",
    "  --train_lang ${TRAIN_LANG} \\\n",
    "  --eval_lang ${EVAL_LANG}\n",
    "```\n",
    "\n",
    "Since you may be making your own changes for experimentation, it is HIGHLY RECOMMENDED to clone the Xtreme repo into your GDrive.\n",
    "\n",
    "Finally, we create a run.sh script in the current root directory (```/content```), and paste the following commands:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "source activate xtreme\n",
    "cd drive/MyDrive/ # Optional but recommended\n",
    "cd xtreme\n",
    "bash scripts/train.sh bert-base-multilingual-cased chaii_hi\n",
    "```\n",
    "\n",
    "Your model should be stored in ```xtreme/outputs-temp/```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ww3D25ezeMIT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/site-packages (0.3.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/site-packages (from ipython-autotime) (7.25.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (5.0.9)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (5.0.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (3.0.19)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (0.1.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (2.9.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/site-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/site-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/site-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/site-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "Fine-tuning bert-base-multilingual-cased on chaii_hi using GPU 0\n",
      "Load data from /root/mount/dataset, and save models to /root/xtreme/outputs-temp/\n",
      "07/30/2021 04:46:06 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "07/30/2021 04:46:07 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /root/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
      "07/30/2021 04:46:07 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "07/30/2021 04:46:08 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "07/30/2021 04:46:09 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "07/30/2021 04:46:24 - INFO - transformers.modeling_utils -   Weights of BertForQuestionAnswering not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "07/30/2021 04:46:24 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "07/30/2021 04:46:24 - INFO - __main__ -   lang2id = None\n",
      "07/30/2021 04:46:25 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/root/mount/dataset', device=device(type='cpu'), do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, eval_all_checkpoints=False, eval_lang='hi', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=4, learning_rate=3e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='bert-base-multilingual-cased', model_type='bert', n_best_size=20, n_gpu=0, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=2.0, output_dir='/root/xtreme/outputs-temp//chaii_hi/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=4, predict_file='/root/mount/dataset/dev.hi.qa.jsonl', save_steps=-1, seed=42, server_ip='', server_port='', threads=8, tokenizer_name='', train_file='/root/mount/dataset/train.hi.qa.jsonl', train_lang='hi', verbose_logging=False, version_2_with_negative=False, warmup_steps=500, weight_decay=0.0001)\n",
      "07/30/2021 04:46:25 - INFO - __main__ -   Creating features from dataset file at /root/mount/dataset\n",
      "100%|| 598/598 [00:05<00:00, 109.97it/s]\n",
      "convert squad examples to features:  16%|     | 97/598 [00:54<03:46,  2.21it/s]/root/xtreme/scripts/train_qa.sh: line 84:   139 Killed                  CUDA_VISIBLE_DEVICES=$GPU python third_party/run_squad.py --model_type ${MODEL_TYPE} --model_name_or_path ${MODEL} --do_lower_case --do_train --do_eval --data_dir ${TASK_DATA_DIR} --train_file ${TRAIN_FILE} --predict_file ${PREDICT_FILE} --per_gpu_train_batch_size 4 --learning_rate ${LR} --num_train_epochs ${NUM_EPOCHS} --max_seq_length $MAXL --doc_stride 128 --save_steps -1 --overwrite_output_dir --gradient_accumulation_steps 4 --warmup_steps 500 --output_dir ${MODEL_PATH} --weight_decay 0.0001 --threads 8 --train_lang ${TRAIN_LANG} --eval_lang ${EVAL_LANG}\n",
      "************************\n",
      "bert-base-multilingual-cased\n",
      "************************\n",
      "\n",
      "Predictions on chaii_hi\n",
      "time: 2min 24s (started: 2021-07-30 04:45:53 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Now that the data is downloaded, you can run the training script directly from the repo. Here the best way to do it, is to create a new file called run.sh in home folder, and copy paste the below commands, then just run this cell:\n",
    "# Also ensure that you set your runtime type to GPU for training.\n",
    "'''\n",
    "#!/bin/bash\n",
    "\n",
    "source activate xtreme\n",
    "cd drive/MyDrive/\n",
    "cd xtreme\n",
    "bash scripts/train.sh bert-base-multilingual-cased chaii_hi\n",
    "'''\n",
    "\n",
    "!pip install ipython-autotime\n",
    "%load_ext autotime\n",
    "\n",
    "!bash /root/run.sh /root/mount/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmVxDvoTuew6"
   },
   "source": [
    "## Inference and Evaluation\n",
    "\n",
    "For inference, we do the following modifications to Xtreme repo:\n",
    "1. In ```predict_qa.sh```, add the following (line 40):\n",
    "```\n",
    "elif [ $TGT == 'chaii_hi' ]; then\n",
    "  langs=( hi )\n",
    "```\n",
    "\n",
    "\n",
    "Also, we create a bash file (similar to ```run.sh```) called ```predict.sh```, and copy the commands below into it:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "source activate xtreme\n",
    "cd drive/MyDrive/\n",
    "cd xtreme\n",
    "\n",
    "MODEL_PATH=\"/content/drive/MyDrive/xtreme/outputs-temp/chaii_hi/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\"\n",
    "GPU=-0\n",
    "DATA_DIR=\"/content/drive/MyDrive/\"\n",
    "\n",
    "bash scripts/predict_qa.sh bert-base-multilingual-cased bert chaii_hi $MODEL_PATH chaii_hi $GPU $DATA_DIR\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNbJn6KoNIMg"
   },
   "outputs": [],
   "source": [
    "# First, you need to run inference on the models\n",
    "\n",
    "!bash predict.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlPo9R0Duc3U"
   },
   "outputs": [],
   "source": [
    "# Before you can start local evaluation, we need to put files in a particular format. Run the below command to transfer predictions and labels\n",
    "# Copy dev data\n",
    "%%bash\n",
    "\n",
    "cd drive/MyDrive # Optional but recommended\n",
    "\n",
    "TASK_NAME=\"chaii_hi\"\n",
    "mkdir -p eval_dir/predictions/$TASK_NAME/\n",
    "mkdir -p eval_dir/labels/$TASK_NAME/\n",
    "\n",
    "GOLD_DATA_LOCATION=\"/content/drive/MyDrive/chaii_data/\"\n",
    "\n",
    "cp $GOLD_DATA_LOCATION/* eval_dir/labels/$TASK_NAME/\n",
    "for file in eval_dir/labels/$TASK_NAME/dev.*.jsonl; do\n",
    "filename=$(basename \"$file\")\n",
    "fname=\"${filename%.*}\"\n",
    "lg=$(echo $fname | cut -d\".\" -f 2)\n",
    "mv $file eval_dir/labels/$TASK_NAME/test-$lg.json\n",
    "done\n",
    "\n",
    "cp xtreme/predictions/$TASK_NAME/predictions* eval_dir/predictions/$TASK_NAME/\n",
    "for file in eval_dir/predictions/$TASK_NAME/predictions*.json; do\n",
    "filename=$(basename \"$file\")\n",
    "fname=\"${filename%.*}\"\n",
    "lg=$(echo $fname | cut -d\"_\" -f 2)\n",
    "mv $file eval_dir/predictions/tydiqa/test-$lg.json\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Mkrngi9hlJQ"
   },
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "%%bash\n",
    "source activate xtreme\n",
    "cd xtreme/\n",
    "python evaluate.py --prediction_folder /content/eval_dir/predictions --label_folder /content/eval_dir/labels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YP4_O2spMxYW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/content/drive/MyDrive/xtreme/outputs-temp/chaii_hi/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384/predictions_hi_.json\") as f:\n",
    "  preds = json.load(f)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/chaii_data/dev.hi.qa.jsonl\") as f:\n",
    "  dev_data = json.load(f)\n",
    "\n",
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qugMjeD1d1_m"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "dev_answer_pair_matches = []\n",
    "for d in dev_data['data']:\n",
    "  for para in d['paragraphs']:\n",
    "    for qa in para['qas']:\n",
    "      dev_answer_pair_matches.append({'context':para['context'],'question':qa['question'],'gold_answer':qa['answers'],'mbert_pred':preds[qa['id']],'id':qa['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72LNd7Mvedgv"
   },
   "outputs": [],
   "source": [
    "pprint(dev_answer_pair_matches[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spOJDJpZgHmF"
   },
   "outputs": [],
   "source": [
    "#Matches in predictions\n",
    "correct_ans = [d for d in dev_answer_pair_matches if d['mbert_pred']==d['gold_answer'][0]['text']]\n",
    "with open('/content/drive/MyDrive/correct_chaii_hi_mbert.txt','w',encoding='utf-8') as f:\n",
    "  for c in correct_ans:\n",
    "    f.write(f\"id:{c['id']}\\n\")\n",
    "    f.write(f\"context:{c['context']}\\n\")\n",
    "    f.write(f\"question:{c['question']}\\n\")\n",
    "    f.write(f\"gold_answer:{c['gold_answer'][0]['text']}\\n\")\n",
    "    f.write(f\"mbert_pred:{c['mbert_pred']}\\n\")\n",
    "    f.write(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JHfrNyPhrJW"
   },
   "outputs": [],
   "source": [
    "#Mismatches in predictions\n",
    "wrong_ans = [d for d in dev_answer_pair_matches if d['mbert_pred']!=d['gold_answer'][0]['text']]\n",
    "with open('/content/drive/MyDrive/wrong_chaii_hi_mbert.txt','w',encoding='utf-8') as f:\n",
    "  for c in wrong_ans:\n",
    "    f.write(f\"id:{c['id']}\\n\")\n",
    "    f.write(f\"context:{c['context']}\\n\")\n",
    "    f.write(f\"question:{c['question']}\\n\")\n",
    "    f.write(f\"gold_answer:{c['gold_answer'][0]['text']}\\n\")\n",
    "    f.write(f\"mbert_pred:{c['mbert_pred']}\\n\")\n",
    "    f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84li0T-PlJdi"
   },
   "outputs": [],
   "source": [
    "len(correct_ans),len(wrong_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-FWJFCol_Du"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ChAII_COPY.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
