{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/abisubramanya27/ChAII-docker/blob/master/ChAII_COPY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTwSEAbMVIBn"
   },
   "source": [
    "Env Setup (Check out https://towardsdatascience.com/conda-google-colab-75f7c867a522 for detailed instructions)\n",
    "BEFORE STARTING, SET RUNTIME_TYPE TO GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVtit-4yq6rg"
   },
   "source": [
    "# ChAII starter notebook\n",
    "\n",
    "This is a starter notebook for running a baseline mBERT model on the task. This is a standalone notebook which will allow you to do the following:\n",
    "1. Train an mBERT model on the ChAII data (utilizing Colab GPUs), \n",
    "2. Get dev evaluation numbers, \n",
    "3. Generate a submission for the Kaggle leaderboard with the appropriate format.\n",
    "\n",
    "This notebook uses the [Xtreme](https://github.com/google-research/xtreme) codebase for training QA-finetuned models. Feel free to run your own scripts/variants locally, experiment with other models and pipelines, not necessarily limited to Xtreme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Zqk1MjtVndG",
    "outputId": "db2c31d4-283b-4a2c-e3db-7596e5c8b541"
   },
   "outputs": [],
   "source": [
    "# Verify PYTHONPATH is blank to avoid problems later\n",
    "!echo $PYTHONPATH # should return <blank>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_-aluEdaDTO",
    "outputId": "1d505c78-8b7a-4f34-f3b2-8e10f21eed93"
   },
   "outputs": [],
   "source": [
    "# Verify that Miniconda installation and updation worked\n",
    "\n",
    "!which conda # should return /usr/local/bin/conda\n",
    "!conda --version # should return 4.10.3\n",
    "!which python # should return /usr/local/bin/python\n",
    "!python --version # should return Python 3.6.13 :: Anaconda, Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hmrAJyYMabHA",
    "outputId": "2c4fa3ed-9a53-44b7-acf9-162c176acd76"
   },
   "outputs": [],
   "source": [
    "# Overview of path files\n",
    "\n",
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4DVHoBlCuAa"
   },
   "source": [
    "## Training\n",
    "\n",
    "Although this codebase can be used for many varieties of training methods and experiments, we will only train a straightforward baseline. We will create a monolingual Hindi QA model. We encourage you to read and experiment with the Xtreme codebase, and also with other repos. Some promising avenues:\n",
    "\n",
    "* Train model on both Hindi and Tamil ChAII data,\n",
    "* Multi-task learning with Xtreme,\n",
    "* Annotate your own data into a QA format and augment training,\n",
    "* Zero-shot transfer learning\n",
    "\n",
    "The cells below do the following:\n",
    "\n",
    "1. Convert the given ChAII data (from competition) to QA (SQuAD) format, split into train and dev sets.\n",
    "2. Finetune mBERT (bert-base-multilingual-cased) on the ChAII data.\n",
    "3. Save the model and dev predictions into GDrive for evaluation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "aE9wX7A8D-me",
    "outputId": "38ff7707-6fd1-4eb7-88d9-211643eb2df7"
   },
   "outputs": [],
   "source": [
    "# Load ChAII dataset\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import functools\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", None)\n",
    "\n",
    "data_path = Path(\"/root/mount/dataset\")\n",
    "json_dicts = []\n",
    "\n",
    "def get_dataframe(file_path):\n",
    "    df = pd.DataFrame()\n",
    "    with open(file_path,'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    df = df.astype(str)\n",
    "    df = df.apply(lambda x: x.str.strip())\n",
    "    return df\n",
    "\n",
    "chaii_data = get_dataframe(data_path / \"train.csv\")\n",
    "chaii_data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwbfBnSXDcQk"
   },
   "source": [
    "### Data conversion to QA format\n",
    "\n",
    "The below cells convert TyDiQA and ChAII Kaggle data format to the SQuAD QA format, so it can be used with the Xtreme pipeline. You need to download the ChAII data from Kaggle, and put it in the mount/dataset directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert from Kaggle training format to QA format\n",
    "language = 'hindi' # replace this with tamil when processing tamil dataset\n",
    "lang_code = 'hi' # for tamil use ta\n",
    "\n",
    "def convert_to_qa_format_kaggle(row):\n",
    "    answer = {}\n",
    "    answer[\"text\"] = row[\"answer_text\"]\n",
    "    answer[\"answer_start\"] = int(row[\"answer_start\"])\n",
    "    qa_json = {\n",
    "        \"title\": \"\",\n",
    "        \"paragraphs\": [\n",
    "            {\n",
    "                \"context\": row[\"context\"],\n",
    "                \"qas\": [\n",
    "                    {\n",
    "                        \"question\": row[\"question\"],\n",
    "                        \"id\": row[\"language\"] + '-' + str(row[\"id\"]),\n",
    "                        \"answers\": [answer]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    return qa_json\n",
    "\n",
    "# Process one language at a time\n",
    "# Here chaii_data is a pandas dataframe\n",
    "def get_qa_data_from_kaggle_format(chaii_data, language): \n",
    "    language = 'hindi'\n",
    "\n",
    "    qa_data = {\"data\":[], \"version\":f\"chaii_{language}\"}\n",
    "    for index, row in chaii_data.iterrows():\n",
    "        if row[\"language\"] == language:\n",
    "            qa_datapoint = convert_to_qa_format_kaggle(row)\n",
    "            qa_data[\"data\"].append(qa_datapoint)\n",
    "\n",
    "    print(\"QA (SQuAD) format:\")\n",
    "    print(qa_data[\"data\"][0])\n",
    "    return qa_data\n",
    "\n",
    "qa_data = get_qa_data_from_kaggle_format(chaii_data, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf6zv9YfJD5D"
   },
   "outputs": [],
   "source": [
    "print(\"Total number of datapoints: %d\" % len(qa_data[\"data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN5l8MNZJHy1"
   },
   "outputs": [],
   "source": [
    "# Split datapoints language-wise and into QA format\n",
    "# Run this cell only if you need to convert from TyDiQA to SQuAD format, otherwise run the nexy one.\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "def byte_str(text):\n",
    "  return text.encode(\"utf-8\")\n",
    "\n",
    "def byte_len(text):\n",
    "  # Python 3 encodes text as character sequences, not byte sequences\n",
    "  # (like Python 2).\n",
    "  return len(byte_str(text))\n",
    "\n",
    "def byte_slice(text, start, end, errors=\"replace\"):\n",
    "  # Python 3 encodes text as character sequences, not byte sequences\n",
    "  # (like Python 2).\n",
    "  return byte_str(text)[start:end].decode(\"utf-8\", errors=errors)\n",
    "\n",
    "def convert_to_qa_format_tydiqa(tydi_json):\n",
    "  answer = {}\n",
    "  for annotation in tydi_json[\"annotations\"]:\n",
    "    minimal_answer = annotation[\"minimal_answer\"]\n",
    "    if minimal_answer[\"plaintext_start_byte\"] != -1 and minimal_answer[\"plaintext_end_byte\"] != -1:\n",
    "      answer[\"text\"] = byte_slice(tydi_json[\"document_plaintext\"],minimal_answer[\"plaintext_start_byte\"],minimal_answer[\"plaintext_end_byte\"])\n",
    "      answer[\"answer_start\"] = [m.start() for m in re.finditer(answer[\"text\"],tydi_json[\"document_plaintext\"])][0]\n",
    "      break\n",
    "  if answer == {}:\n",
    "    return {}\n",
    "  \n",
    "  qa_json = {\n",
    "      \"title\" : tydi_json[\"document_title\"],\n",
    "      \"paragraphs\" : [\n",
    "                      {\n",
    "                          \"context\": tydi_json[\"document_plaintext\"],\n",
    "                          \"qas\" : [\n",
    "                                   {\n",
    "                                    \"question\" : tydi_json[\"question_text\"],\n",
    "                                    \"id\" : tydi_json[\"language\"] + '-' + str(tydi_json[\"example_id\"]),\n",
    "                                    \"answers\" : [answer],\n",
    "                                   }\n",
    "                          ]\n",
    "                      }\n",
    "      ],\n",
    "  }\n",
    "\n",
    "  return qa_json\n",
    "\n",
    "# Here chaii_data is json list\n",
    "def get_qa_data_from_tydiqa_format(chaii_data, language):\n",
    "    language = 'hindi'\n",
    "    qa_data = {\"data\":[], \"version\":f\"chaii_{language}\"}\n",
    "    for json_dict in json_dicts:\n",
    "      if json_dict[\"language\"] == language:\n",
    "        qa_datapoint = convert_to_qa_format_tydiqa(json_dict)\n",
    "        if qa_datapoint != {}:\n",
    "          qa_data[\"data\"].append(qa_datapoint)\n",
    "        qa_data['data'].append(json_dict)\n",
    "\n",
    "    print(\"QA (SQuAD) format:\")\n",
    "    print(qa_data[\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5se7aK7JoGM"
   },
   "outputs": [],
   "source": [
    "# Splitting data into train and dev and saving converted QA formats\n",
    "\n",
    "import random\n",
    "\n",
    "qa_data_datapoints = qa_data[\"data\"]\n",
    "random.shuffle(qa_data_datapoints)\n",
    "train_size = int(len(qa_data_datapoints)*0.8)\n",
    "train_qa_data_datapoints, dev_qa_data_datapoints = qa_data_datapoints[:train_size], qa_data_datapoints[train_size:]\n",
    "\n",
    "train_qa_data = {\"data\":train_qa_data_datapoints, \"version\":f\"chaii_{lang_code}_train\"}\n",
    "dev_qa_data = {\"data\":dev_qa_data_datapoints, \"version\":f\"chaii_{lang_code}_dev\"}\n",
    "\n",
    "with open(os.path.join(data_path,f\"train.{lang_code}.qa.jsonl\"),'w') as f:\n",
    "  json.dump(train_qa_data,f)\n",
    "\n",
    "with open(os.path.join(data_path,f\"dev.{lang_code}.qa.jsonl\"),'w') as f:\n",
    "  json.dump(dev_qa_data,f)\n",
    "\n",
    "print(\"Training data size: %d\" % len(train_qa_data_datapoints))\n",
    "print(\"Dev data size: %d\" % len(dev_qa_data_datapoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scuzryHrPzHV"
   },
   "source": [
    "The cell below is optional (we have not used it for our baseline model), but it downloads the original TyDiQA data in the QA format. You can combine it with our ChAII data and boost training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ta0K5sV8b6nk"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Downloading the data. For baseline, we can ignore the other training datasets for other tasks, and focus on training with just TyDiQA data. \n",
    "\n",
    "source activate xtreme\n",
    "cd /root/xtreme # Optional but recommended\n",
    "\n",
    "# Copyright 2020 Google and DeepMind.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "REPO=$PWD\n",
    "DIR=$REPO/download/\n",
    "mkdir -p $DIR\n",
    "\n",
    "function download_tydiqa {\n",
    "    echo \"download tydiqa-goldp\"\n",
    "    base_dir=$DIR/tydiqa/\n",
    "    mkdir -p $base_dir && cd $base_dir\n",
    "    tydiqa_train_file=tydiqa-goldp-v1.1-train.json\n",
    "    tydiqa_dev_file=tydiqa-goldp-v1.1-dev.tgz\n",
    "    wget https://storage.googleapis.com/tydiqa/v1.1/${tydiqa_train_file} -q --show-progress\n",
    "    wget https://storage.googleapis.com/tydiqa/v1.1/${tydiqa_dev_file} -q --show-progress\n",
    "    tar -xf ${tydiqa_dev_file}\n",
    "    rm ${tydiqa_dev_file}\n",
    "    out_dir=$base_dir/tydiqa-goldp-v1.1-train\n",
    "    python $REPO/utils_preprocess.py --data_dir $base_dir --output_dir $out_dir --task tydiqa\n",
    "    mv $base_dir/$tydiqa_train_file $out_dir/\n",
    "    echo \"Successfully downloaded data at $DIR/tydiqa\" >> $DIR/download.log\n",
    "}\n",
    "\n",
    "download_tydiqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZX8uTFPfQQJR"
   },
   "source": [
    "### Training mBERT on Hindi ChAII data\n",
    "\n",
    "The below script uses the Xtreme script to train the data. Here, we need to modify the code in the folders to train it on the ChAII data. You can double click on the scripts, modify the code and change them. \n",
    "\n",
    "For the baseline, the following changes were made to the Xtreme repo code:\n",
    "\n",
    "\n",
    "1.   In ```scripts/train.sh```, an additional task called \"chaii_hi\" was added as such:\n",
    "```\n",
    "...\n",
    "elif [ $TASK == 'chaii_hi' ]; then\n",
    "  bash $REPO/scripts/train_qa.sh $MODEL chaii_hi $TASK $GPU $DATA_DIR $OUT_DIR\n",
    "...\n",
    "```\n",
    "2.   In ```scripts/train_qa.sh```, the following flags were added:\n",
    "```\n",
    "TRAIN_LANG=\"en\"\n",
    "EVAL_LANG=\"en\"\n",
    "```\n",
    "Another elif condition was added as such to modify path of data dir:\n",
    "```\n",
    "...\n",
    "elif [ $SRC == 'chaii_hi' ]; then\n",
    "  TASK_DATA_DIR=${DATA_DIR}\n",
    "  TRAIN_FILE=${TASK_DATA_DIR}/train.hi.qa.jsonl\n",
    "  PREDICT_FILE=${TASK_DATA_DIR}/dev.hi.qa.jsonl\n",
    "  TRAIN_LANG=\"hi\"\n",
    "  EVAL_LANG=\"hi\"\n",
    "...\n",
    "```\n",
    "Finally, TRAIN_LANG and EVAL_LANG replaced the hardcoded \"en\":\n",
    "```\n",
    " --weight_decay 0.0001 \\\n",
    "  --threads 8 \\\n",
    "  --train_lang ${TRAIN_LANG} \\\n",
    "  --eval_lang ${EVAL_LANG}\n",
    "```\n",
    "\n",
    "If you want to make your own changes for experimentation, clone the xtreme repo locally in the mount folder and mount it as part of the docker container. \n",
    "\n",
    "Finally, we create a run.sh script in the current root directory, and paste the following commands:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "TASK=${1:-chaii_hi}\n",
    "DATA_DIR=${2:-\"/root/xtreme/download/chaii_data/\"}\n",
    "OUT_DIR=${3:-\"/root/xtreme/outputs-temp/\"}\n",
    "MODEL=${4:-bert-base-multilingual-cased}\n",
    "GPU=${5:-0}\n",
    "TRAIN_FILE_NAME=${6}\n",
    "PREDICT_FILE_NAME=${7}\n",
    "\n",
    "source activate xtreme\n",
    "cd /root/xtreme\n",
    "bash scripts/train.sh $MODEL $TASK $GPU $DATA_DIR $OUT_DIR $TRAIN_FILE_NAME $PREDICT_FILE_NAME\n",
    "\n",
    "```\n",
    "\n",
    "Your model should be stored in ```/root/mount/outputs-temp/```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ww3D25ezeMIT"
   },
   "outputs": [],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime\n",
    "\n",
    "# We store all the outputs and models to our local mount directory \n",
    "# For tamil change the task to 'chaii_ta'\n",
    "!bash /root/run.sh chaii_hi \"/root/mount/dataset\" \"/root/mount/outputs-temp\" bert-base-multilingual-cased 0 train.hi.qa.jsonl dev.hi.qa.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmVxDvoTuew6"
   },
   "source": [
    "## Inference and Evaluation\n",
    "\n",
    "For inference, we do the following modifications to Xtreme repo:\n",
    "1. In ```predict_qa.sh```, add the following (line 40):\n",
    "```\n",
    "elif [ $TGT == 'chaii_hi' ]; then\n",
    "  langs=( hi )\n",
    "```\n",
    "\n",
    "\n",
    "Also, we create a bash file (similar to ```run.sh```) called ```predict.sh```, and copy the commands below into it:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "source activate xtreme\n",
    "cd /root/xtreme\n",
    "\n",
    "MODEL_PATH=${1:-\"/root/xtreme/outputs-temp/chaii_hi/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\"}\n",
    "TASK=${2:-chaii_hi}\n",
    "DATA_DIR=${2:-\"/root/xtreme/download/chaii_data/\"}\n",
    "PREDICTIONS_DIR=${3:-\"/root/xtreme/predictions/\"}\n",
    "MODEL=${4:-bert-base-multilingual-cased}\n",
    "MODEL_TYPE=${5:-bert}\n",
    "GPU=${6:-0}\n",
    "PREDICT_FILE_NAME=${7}\n",
    " \n",
    "bash scripts/predict_qa.sh bert-base-multilingual-cased bert $MODEL_PATH $TASK $GPU $DATA_DIR $PREDICTIONS_DIR $PREDICT_FILE_NAME\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNbJn6KoNIMg"
   },
   "outputs": [],
   "source": [
    "# First, you need to run inference on the models\n",
    "\n",
    "!bash /root/predict.sh \"/root/mount/outputs-temp/chaii_hi/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\" \\\n",
    "      chaii_hi \"/root/mount/dataset\" \"/root/eval_dir/predictions\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlPo9R0Duc3U"
   },
   "outputs": [],
   "source": [
    "# Before you can start local evaluation, we need to put files in a particular format. Run the below command to transfer predictions and labels\n",
    "\n",
    "!bash /root/pre_evaluate.sh chaii_hi /root/mount/dataset /root/mount/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Mkrngi9hlJQ"
   },
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "\n",
    "!bash /root/evaluate.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YP4_O2spMxYW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/root/mount/outputs-temp/chaii_hi/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384/predictions_hi_.json\") as f:\n",
    "  preds = json.load(f)\n",
    "\n",
    "with open(\"/root/mount/dataset/dev.hi.qa.jsonl\") as f:\n",
    "  dev_data = json.load(f)\n",
    "\n",
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qugMjeD1d1_m"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "dev_answer_pair_matches = []\n",
    "for d in dev_data['data']:\n",
    "  for para in d['paragraphs']:\n",
    "    for qa in para['qas']:\n",
    "      dev_answer_pair_matches.append({'context':para['context'],'question':qa['question'],'gold_answer':qa['answers'],'mbert_pred':preds[qa['id']],'id':qa['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72LNd7Mvedgv"
   },
   "outputs": [],
   "source": [
    "pprint(dev_answer_pair_matches[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spOJDJpZgHmF"
   },
   "outputs": [],
   "source": [
    "#Matches in predictions\n",
    "correct_ans = [d for d in dev_answer_pair_matches if d['mbert_pred']==d['gold_answer'][0]['text']]\n",
    "with open('/root/mount/correct_chaii_hi_mbert.txt','w',encoding='utf-8') as f:\n",
    "  for c in correct_ans:\n",
    "    f.write(f\"id:{c['id']}\\n\")\n",
    "    f.write(f\"context:{c['context']}\\n\")\n",
    "    f.write(f\"question:{c['question']}\\n\")\n",
    "    f.write(f\"gold_answer:{c['gold_answer'][0]['text']}\\n\")\n",
    "    f.write(f\"mbert_pred:{c['mbert_pred']}\\n\")\n",
    "    f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JHfrNyPhrJW"
   },
   "outputs": [],
   "source": [
    "#Mismatches in predictions\n",
    "wrong_ans = [d for d in dev_answer_pair_matches if d['mbert_pred']!=d['gold_answer'][0]['text']]\n",
    "with open('/root/mount/wrong_chaii_hi_mbert.txt','w',encoding='utf-8') as f:\n",
    "  for c in wrong_ans:\n",
    "    f.write(f\"id:{c['id']}\\n\")\n",
    "    f.write(f\"context:{c['context']}\\n\")\n",
    "    f.write(f\"question:{c['question']}\\n\")\n",
    "    f.write(f\"gold_answer:{c['gold_answer'][0]['text']}\\n\")\n",
    "    f.write(f\"mbert_pred:{c['mbert_pred']}\\n\")\n",
    "    f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84li0T-PlJdi"
   },
   "outputs": [],
   "source": [
    "len(correct_ans),len(wrong_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-FWJFCol_Du"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ChAII_COPY.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
